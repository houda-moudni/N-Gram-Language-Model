{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2-NLP Language Model : *Text Generation, AutoComplete, Autocorrection*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will improve the performance of the Ngram Model then implement the text generation, autocorrector and a method for autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Counter\n",
    "from collections import defaultdict\n",
    "from ast import literal_eval\n",
    "from auto_corrector import Auto_Corrector\n",
    "import configparser\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Handling Configuration File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions manage the `configuration.json` file:\n",
    "\n",
    "- **Checking File Existence:** Verifying if the configuration file exists.\n",
    "- **Reading File Line by Line:** Reading the contents of the configuration file line by line.\n",
    "- **Loading JSON Configuration:** Loading the JSON data from the configuration file and handling any exceptions that may occur during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(text):\n",
    "    with open(text, \"r\", encoding=\"utf-8\") as file:\n",
    "        all_lines = file.readlines()\n",
    "    return all_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exists(file_path):\n",
    "    return os.path.exists(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return data\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File '{file_path}' not found.\")\n",
    "        return None\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"decoding JSON... {e}\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred:{e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_json(data, file_path):\n",
    "    try:\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(data, json_file)\n",
    "            logging.info(f\"Dictionary saved to '{file_path}' successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred:{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Building the Ngram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NgramLanguageModel:\n",
    "\n",
    "    \"\"\" \n",
    "        This class represents an N-gram language model for text generation, autocorrection and textcomplete.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        ngram_size : int\n",
    "            The size of the N-grams used in the model.\n",
    "\n",
    "        unigram_counts : Counter\n",
    "            Counter object to store counts of individual words.\n",
    "\n",
    "        trigram_counts : Counter\n",
    "            Counter object to store counts of trigrams.\n",
    "\n",
    "        bigram_counts : Counter\n",
    "            Counter object to store counts of bigrams.\n",
    "\n",
    "        probabilities_bigram : dict\n",
    "            Dictionary to store probabilities of bigrams.\n",
    "\n",
    "        probabilities_trigram : dict\n",
    "            Dictionary to store probabilities of trigrams.\n",
    "\n",
    "        k : float\n",
    "            Smoothing parameter for Laplace smoothing.\n",
    "\n",
    "        alphabets : str\n",
    "            Regular expression pattern for alphabetic characters.\n",
    "\n",
    "        prefixes : str\n",
    "            Regular expression pattern for prefixes.\n",
    "\n",
    "        suffixes : str\n",
    "            Regular expression pattern for suffixes.\n",
    "\n",
    "        starters : str\n",
    "            Regular expression pattern for sentence starters.\n",
    "\n",
    "        acronyms : str\n",
    "            Regular expression pattern for acronyms.\n",
    "\n",
    "        websites : str\n",
    "            Regular expression pattern for website URLs.\n",
    "\n",
    "        digits : str\n",
    "            Regular expression pattern for digits.\n",
    "\n",
    "        multiple_dots : str\n",
    "            Regular expression pattern for multiple consecutive dots.\n",
    "\n",
    "        characters : list\n",
    "            List of characters used for replacements.\n",
    "\n",
    "        replacements : dict\n",
    "            Dictionary for character replacements.\n",
    "\n",
    "        lines_processed : int\n",
    "            Number of lines processed during training.\n",
    "        \"\"\" \n",
    "\n",
    "    def __init__(self, ngram_size):\n",
    "        \n",
    "        logging.basicConfig(filename='ngram_language_model.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "        \"\"\" \n",
    "        Initialize the NgramLanguageModel object with the specified N-gram size.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ngram_size : int\n",
    "            The size of the N-grams used in the model.\n",
    "        \"\"\" \n",
    "        \n",
    "        logging.info(\"Initializing NgramLanguageModel with ngram size: %d\", ngram_size)\n",
    "        file_path = 'configuration.json'\n",
    "\n",
    "        # cheking if the configuration file exist if not the constructor initialize the variale and save them in the configuration file\n",
    "\n",
    "        if  not file_exists(file_path):\n",
    "            logging.info(\"Configuration file doesn't exist. Initializing variables and saving to configuration file.\")\n",
    "\n",
    "            self.ngram_size = ngram_size\n",
    "\n",
    "            self.unigram_counts = Counter()\n",
    "            self.trigram_counts = Counter()\n",
    "            self.bigram_counts = Counter()\n",
    "\n",
    "            self.probabilities_bigram = defaultdict()\n",
    "            self.probabilities_trigram = defaultdict()\n",
    "\n",
    "            self.k = 0.01\n",
    "\n",
    "            self.alphabets= \"([A-Za-z])\"\n",
    "            self.prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "            self.suffixes = \"(Inc|Ltd|Jr|Sr|Co|www)\"\n",
    "            self.starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "            self.acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "            self.websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
    "            self.digits = \"([0-9])\"\n",
    "            self.multiple_dots = r'\\.{2,}'\n",
    "\n",
    "            self.characters = [\"‚Äù\", \"\\\"\", \"!\", \"!\", \"?\"]\n",
    "            self.replacements = {'.': '.<stop>', '?': '?<stop>', '!': '!<stop>',':)':':)<stop>', '<prd>': '.','/n':' ', '#': '<hashtag>'}\n",
    "\n",
    "            self.lines_processed = 0\n",
    "\n",
    "            self.save_configurations()\n",
    "\n",
    "        # if the configuration file already exist the contrustor load it and intialize the variable with the value in the configuration file\n",
    "        else:\n",
    "\n",
    "          try:\n",
    "\n",
    "            logging.info(\"Loading configurations from existing configuration file.\")\n",
    "\n",
    "            setup = configparser.ConfigParser()\n",
    "            setup.read('config.ini')\n",
    "\n",
    "            configuration = load_json(file_path)\n",
    "            dictionary = configuration[\"dictionary\"]\n",
    "\n",
    "            self.ngram_size = dictionary[\"ngram_size\"]\n",
    "\n",
    "            self.ngram_size = ngram_size\n",
    "            \n",
    "            self.unigram_counts =  Counter(dictionary[\"unigram_count\"])\n",
    "            self.trigram_counts = Counter(dictionary[\"trigram_count\"])\n",
    "            self.bigram_counts = Counter(dictionary[\"bigram_count\"])\n",
    "\n",
    "            self.probabilities_bigram = dictionary[\"probabilities_bigram\"]\n",
    "            self.probabilities_trigram = dictionary[\"probabilities_trigram\"]\n",
    "\n",
    "\n",
    "            self.k = literal_eval(setup['settings'][\"k\"]) \n",
    "\n",
    "            self.alphabets= setup['settings'][\"alphabets\"]\n",
    "            self.prefixes = setup['settings'][\"prefixes\"]\n",
    "            self.suffixes =  setup['settings'][\"suffixes\"]\n",
    "            self.starters = setup['settings'][\"starters\"]\n",
    "            self.acronyms = setup['settings'][\"acronyms\"]\n",
    "            self.websites = setup['settings'][\"websites\"]\n",
    "            self.digits = setup['settings'][\"digits\"]\n",
    "            self.multiple_dots = setup['settings'][\"multiple_dots\"]\n",
    "\n",
    "            self.characters =literal_eval(setup['settings'][\"characters\"]) \n",
    "            self.replacements =literal_eval(setup['settings'][\"replacements\"]) \n",
    "\n",
    "            self.lines_processed =literal_eval( setup['settings'][\"lines_processed\"])\n",
    "            \n",
    "\n",
    "          except Exception as e :\n",
    "            logging.error(\"Error occurred during initialization: %s\", e)\n",
    "\n",
    "\n",
    "    def split_into_sentences(self,text):\n",
    "\n",
    "        \"\"\" \n",
    "        Split the input text into sentences and preprocess each sentence.\n",
    "\n",
    "        This method splits a text into sentences by the tag <stop>, considering various sentence delimiters \n",
    "        and respecting prefixes, suffixes, acronyms, etc. It also transforms the text into lowercase format.\n",
    "        ps : an end of a sentence is defined by !, ?, ., :) + the . does not only define a end of a sentence! \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            The input text to be split into sentences.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The preprocessed text with <stop> tags indicating the end of sentences.\n",
    "        \"\"\" \n",
    "\n",
    "        text = text.replace(\"\\n\",\" \")\n",
    "        text = re.sub(self.prefixes,\"\\\\1<prd>\",text)\n",
    "        text = re.sub(self.websites,\"<prd>\\\\1\",text)\n",
    "        text = re.sub(self.digits + \"[.]\" + self.digits,\"\\\\1<prd>\\\\2\",text)\n",
    "        text = re.sub(self.multiple_dots, lambda match: \"<prd>\" * len(match.group(0)) + \"<stop>\", text)\n",
    "\n",
    "        if \"Ph.D\" in text: text = text.replace(\"Ph.D\",\"Ph<prd>D\")\n",
    "\n",
    "        text = re.sub(\"\\s\" + self.alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "        text = re.sub(self.acronyms+\" \"+self.starters,\"\\\\1<stop> \\\\2\",text)\n",
    "        text = re.sub(self.alphabets + \"[.]\" + self.alphabets + \"[.]\" + self.alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "        text = re.sub(self.alphabets + \"[.]\" + self.alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "        text = re.sub(\" \"+self.suffixes+\"[.] \"+self.starters,\" \\\\1<stop> \\\\2\",text)\n",
    "        text = re.sub(\" \"+self.suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "        text = re.sub(\" \" + self.alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "        text = re.sub(r'[!?.,|]+', lambda match: match.group(0)[0], text)\n",
    "\n",
    "        text = text.replace(\".‚Äù\",\"‚Äù.\")\n",
    "        for char in self.characters:\n",
    "            if char in text:\n",
    "                text = text.replace(f\"{char}\\\"\", f\"\\\"{char}\")\n",
    "\n",
    "        for char, replacement in self.replacements.items():\n",
    "            text = text.replace(char, replacement)\n",
    "\n",
    "        text = text.lower()\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "    def prepare_data(self,file,batch_size = 300) -> list[str]:\n",
    "\n",
    "        \"\"\" \n",
    "        Preprocess the training data and count N-grams.\n",
    "\n",
    "        This method processes the training data by splitting it into sentences, extracting tokens, \n",
    "        replacing low-frequency words with '<unk>', and counting unigrams, bigrams, and trigrams.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file : str\n",
    "            File path to the training corpus.\n",
    "\n",
    "        batch_size : int, optional\n",
    "            Number of lines to process at once, by default 1.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            counts for unigrams, bigrams, and trigrams.\n",
    "        \"\"\" \n",
    "\n",
    "        text_lines = read_file(file)\n",
    "\n",
    "        for i in range(self.lines_processed, len(text_lines),batch_size):\n",
    "\n",
    "            selected_lines = text_lines[i:(min(i + batch_size, len(text_lines)))]\n",
    "            text = \"\"\n",
    "            for s in selected_lines:\n",
    "                text +=  s + \" \"\n",
    "            text = self.split_into_sentences(text)\n",
    "            sentences = text.split(\"<stop>\")\n",
    "            sentences = [s.strip().lower() for s in sentences]\n",
    "            sentences = ['<s> '* (self.ngram_size -1) + item + \" </s>\" for item in sentences]\n",
    "\n",
    "            if sentences and not sentences[-1]: sentences = sentences[:-1]\n",
    "\n",
    "            for s in sentences:\n",
    "                matches = re.findall(r'\\b(?![<>\\w]*>)\\w+\\b|<s>|<unk>|</s>|[.,?!]', s)\n",
    "                self.unigram_counts += Counter(matches)\n",
    "                self.bigram_counts += Counter([matches[i].strip()+\" \"+matches[i+1].strip() for i in range(len(matches)-1)])\n",
    "                self.trigram_counts += Counter([matches[i].strip()+\" \"+matches[i+1].strip()+\" \"+matches[i+2].strip() for i in range(len(matches)-2)])\n",
    "\n",
    "                \n",
    "            self.lines_processed = min(i + batch_size,len(text_lines))\n",
    "            print(f\"Line {i} Successfully proccessed\")\n",
    "            logging.info(f\"Line {i} Successfully proccessed\")\n",
    "            try:\n",
    "                self.save_configurations()\n",
    "            except:\n",
    "                print(f\"failed to save batch number {i}\")\n",
    "                logging.warning(f\"failed to save batch number {i}\")\n",
    "\n",
    "        counter_one = 0\n",
    "        for key, value in self.unigram_counts.items():\n",
    "            if value <= 1:\n",
    "                counter_one+=value\n",
    "\n",
    "        modified_counter = Counter({key if value > 1 else '<unk>': value for key, value in self.unigram_counts.items()})\n",
    "        modified_counter['<unk>'] = counter_one\n",
    "\n",
    "        modified_bigram_counter = Counter()\n",
    "\n",
    "        for combo in self.bigram_counts.keys():\n",
    "            word1, word2 = combo.split(\" \")[0].strip(), combo.split(\" \")[1].strip()\n",
    "            word1 = word1 if word1 in modified_counter.keys() else '<unk>'\n",
    "            word2 = word2 if word2 in modified_counter.keys() else '<unk>'\n",
    "            if word1 + \" \" + word2 in modified_bigram_counter.keys():\n",
    "                modified_bigram_counter[word1 + \" \" + word2] +=  self.bigram_counts[combo]\n",
    "            else:\n",
    "                modified_bigram_counter[word1 + \" \" + word2] =  self.bigram_counts[combo]\n",
    "\n",
    "        modified_trigram_counter = Counter()\n",
    "\n",
    "        for combo in self.trigram_counts.keys():\n",
    "\n",
    "            word1, word2, word3, = combo.split(\" \")[0].strip(), combo.split(\" \")[1].strip(), combo.split(\" \")[2].strip()\n",
    "            word1 = word1 if word1 in modified_counter.keys() else '<unk>'\n",
    "            word2 = word2 if word2 in modified_counter.keys() else '<unk>'\n",
    "            word3 = word3 if word3 in modified_counter.keys() else '<unk>'\n",
    "\n",
    "            if word1 + \" \" + word2 + \" \" + word3 in modified_trigram_counter.keys():\n",
    "                modified_trigram_counter[word1 + \" \" + word2 + \" \" + word3] +=  self.trigram_counts[combo]\n",
    "            else:\n",
    "                modified_trigram_counter[word1 + \" \" + word2+ \" \" + word3] =  self.trigram_counts[combo]\n",
    "\n",
    "        return modified_counter , modified_bigram_counter, modified_trigram_counter\n",
    "\n",
    "\n",
    "    def train(self, infile,batch_size = 300):\n",
    "\n",
    "        \"\"\" \n",
    "        Train the N-gram language model on the provided corpus.\n",
    "\n",
    "        This method preprocesses the training data, calculates probabilities of N-grams(using smoothing algorithm),\n",
    "        and saves the model configurations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        infile : str \n",
    "            File path to the training corpus.\n",
    "\n",
    "        batch_size : int, optional\n",
    "            Number of lines to process at once, by default 1.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Probabilities of bigrams or trigrams depending on the ngram_size.\n",
    "        \"\"\" \n",
    "        \n",
    "\n",
    "        unigram , bigram , trigram = self.prepare_data(infile,batch_size)\n",
    "        self.unigram_counts = unigram\n",
    "        self.bigram_counts = bigram\n",
    "        self.trigram_counts = trigram\n",
    "\n",
    "        if self.ngram_size == 2:\n",
    "\n",
    "            nb_tokens = len(set(self.unigram_counts)) \n",
    "\n",
    "            for bigram in self.bigram_counts:\n",
    "                self.probabilities_bigram[bigram] = math.log((self.bigram_counts[bigram] + 1 * self.k) / (self.unigram_counts[bigram.split(\" \")[0].strip()] + nb_tokens * self.k))\n",
    "\n",
    "            self.save_configurations()\n",
    "            return self.probabilities_bigram\n",
    "            \n",
    "        \n",
    "        if self.ngram_size == 3:\n",
    "\n",
    "            nb_tokens = len(set(self.bigram_counts))\n",
    "\n",
    "            for trigram in self.trigram_counts.keys():\n",
    "\n",
    "                self.probabilities_trigram[trigram] = math.log((self.trigram_counts[trigram] + 1 * self.k) / (self.bigram_counts[trigram.split(\" \")[0].strip() + \" \" +trigram.split(\" \")[1].strip()] + nb_tokens * self.k))\n",
    "            \n",
    "            self.save_configurations()\n",
    "            return self.probabilities_trigram\n",
    "       \n",
    "\n",
    "    def predict_ngram(self, sentence):\n",
    "\n",
    "        \"\"\" \n",
    "        Predict the probability of a given sentence using the N-gram language model.\n",
    "\n",
    "        This method preprocesses the input sentence, calculates the probability of the sentence\n",
    "        based on the probabilities of N-grams calculated in the train step, and returns the probability.\n",
    "        In an other way, it look in the dictionary of probabilities, if the combinaison of words exists\n",
    "        it returns its probability else it calculates it\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : str\n",
    "            The input sentence to predict its probability.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The probability of the input sentence according to the N-gram language model.\n",
    "        \"\"\" \n",
    "\n",
    "        probability = 0.0\n",
    "        text  = self.split_into_sentences(sentence)\n",
    "\n",
    "        sentences = text.split(\"<stop>\")\n",
    "        sentences = [s.strip().lower() for s in sentences]\n",
    "\n",
    "        tokens = [s.split(\" \") for s in sentences][0]\n",
    "\n",
    "        corpus = ['<UNK>' if word not in self.unigram_counts else word for word in tokens]\n",
    "\n",
    "\n",
    "        if self.ngram_size==2:\n",
    "\n",
    "            nb_tokens = len(set(self.unigram_counts))\n",
    "            bigrams = Counter(zip(corpus, corpus[1:]))\n",
    "\n",
    "            for bigram in bigrams :\n",
    "\n",
    "                if bigram in self.bigram_counts:\n",
    "                    probability += self.probabilities_bigram[bigram]\n",
    "\n",
    "                else :\n",
    "                    previous_word_count = self.unigram_counts[bigram[0]]\n",
    "                    probability += math.log(1 * self.k / (previous_word_count + nb_tokens * self.k))\n",
    "\n",
    "\n",
    "        elif self.ngram_size == 3:\n",
    "\n",
    "            nb_tokens = len(set(self.bigram_counts))\n",
    "            trigrams = Counter(zip(corpus, corpus[1:], corpus[2:]))\n",
    "\n",
    "            for trigram in trigrams:\n",
    "\n",
    "                if trigram in self.trigram_counts:\n",
    "                    \n",
    "                    probability += self.probabilities_trigram[trigram]\n",
    "\n",
    "                else:\n",
    "\n",
    "                    previous_bigram = (trigram[0], trigram[1])\n",
    "\n",
    "                    if previous_bigram in self.bigram_counts:\n",
    "\n",
    "                        previous_words_count = self.bigram_counts[previous_bigram]\n",
    "                        probability += math.log(1 * self.k / (previous_words_count + nb_tokens * self.k))\n",
    "\n",
    "                    else :\n",
    "                        probability +=  math.log(1 * self.k / nb_tokens * self.k)\n",
    "    \n",
    "        return probability\n",
    "\n",
    "\n",
    "    def generate_text(self):\n",
    "\n",
    "        \"\"\" \n",
    "        Generate a new sentence using the N-gram language model.\n",
    "\n",
    "        This method generates a new sentence by randomly choosing tokens based on the probabilities \n",
    "        of N-grams stored in the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            A newly generated sentence.\n",
    "        \"\"\" \n",
    "\n",
    "        current_token = \"<s> \" * (self.ngram_size - 1)\n",
    "        generated_text = current_token.strip() + \" \"\n",
    "\n",
    "        if self.ngram_size == 2:\n",
    "            while current_token != \"</s> \":\n",
    "                next_tokens = [token for token in self.probabilities_bigram.keys() if token.startswith(current_token)]\n",
    "                if not next_tokens:\n",
    "                    break  \n",
    "\n",
    "                probabilities = [np.exp(-self.probabilities_bigram[token]) for token in next_tokens]\n",
    "                probabilities_sum = sum(probabilities)\n",
    "                probabilities_normalized = [p / probabilities_sum for p in probabilities]\n",
    "\n",
    "                next_token = np.random.choice(next_tokens, p=probabilities_normalized).split(\" \")[1].strip()\n",
    "\n",
    "                current_token = next_token\n",
    "                generated_text += current_token + \" \"\n",
    "\n",
    "        elif self.ngram_size == 3:\n",
    "            while current_token.split(\" \")[1] != \"</s>\":\n",
    "                next_tokens = [token for token in self.probabilities_trigram.keys() if token.startswith(current_token)]\n",
    "                if not next_tokens:\n",
    "                    break  \n",
    "\n",
    "                probabilities = [np.exp(-self.probabilities_trigram[token]) for token in next_tokens]\n",
    "                probabilities_sum = sum(probabilities)\n",
    "                probabilities_normalized = [p / probabilities_sum for p in probabilities]\n",
    "\n",
    "                next_token = np.random.choice(next_tokens, p=probabilities_normalized).split(\" \")[2].strip()\n",
    "\n",
    "                previous_token = current_token.split(\" \")[1].strip()\n",
    "                current_token = previous_token + \" \" + next_token\n",
    "\n",
    "                generated_text += next_token + \" \"\n",
    "\n",
    "        else:\n",
    "            logging.error(\"[Number Exception] number different than 2 or 3\")\n",
    "\n",
    "        return generated_text.strip()\n",
    "    \n",
    "\n",
    "    def auto_complete(self, sentence):\n",
    "\n",
    "        \"\"\" \n",
    "        Generate a the rest of a sentence using the N-gram language model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The rest of a sentence.\n",
    "        \"\"\" \n",
    "\n",
    "        probabilities = self.probabilities_bigram if self.ngram_size==2 else self.probabilities_trigram\n",
    "\n",
    "        text  = self.split_into_sentences(sentence)\n",
    "        sentences = text.split(\"<stop>\")\n",
    "        sentences = [s.strip().lower() for s in sentences]\n",
    "        tokens = [s.split(\" \") for s in sentences][0]\n",
    "\n",
    "\n",
    "        # selecting the last token to base on\n",
    "        words = ['<unk>' if word not in self.unigram_counts else word for word in tokens]\n",
    "        corpus = words[-(self.ngram_size)+1:]\n",
    "\n",
    "        current_token = \"\"\n",
    "        generated_text = \"\"\n",
    "\n",
    "        for word in corpus:\n",
    "            current_token += word.strip() +\" \"\n",
    "\n",
    "        if self.ngram_size == 2:\n",
    "\n",
    "            while current_token != \"</s> \":\n",
    "\n",
    "                next_tokens = [token for token in probabilities.keys() if token.startswith(current_token.strip())]\n",
    "\n",
    "                if not next_tokens:\n",
    "                    break  # No next tokens available, end the generation\n",
    "\n",
    "                probabilities_ = [np.exp(-probabilities[token]) for token in next_tokens]\n",
    "                probabilities_sum = sum(probabilities_)\n",
    "                probabilities_normalized = [p / probabilities_sum for p in probabilities_]\n",
    "\n",
    "                next_token = np.random.choice(next_tokens, p=probabilities_normalized).split(\" \")[1].strip()\n",
    "\n",
    "                current_token = next_token\n",
    "                if next_token != '</s>':\n",
    "                    generated_text += next_token + \" \"\n",
    "\n",
    "        elif self.ngram_size == 3:\n",
    "\n",
    "            while current_token.split(\" \")[1] != \"</s>\":\n",
    "\n",
    "                next_tokens = [token for token in probabilities.keys() if token.startswith(current_token.strip())]\n",
    "\n",
    "                if not next_tokens:\n",
    "                    break  # No next tokens available, end the generation\n",
    "\n",
    "                probabilities_ = [np.exp(-probabilities[token]) for token in next_tokens]\n",
    "                probabilities_sum = sum(probabilities_)\n",
    "                probabilities_normalized = [p / probabilities_sum for p in probabilities_]\n",
    "\n",
    "                next_token = np.random.choice(next_tokens, p=probabilities_normalized).split(\" \")[2].strip()\n",
    "\n",
    "                previous_token = current_token.split(\" \")[1].strip()\n",
    "                current_token = previous_token + \" \" + next_token\n",
    "\n",
    "                if next_token != '</s>':\n",
    "                    generated_text += next_token + \" \"\n",
    "\n",
    "        else:\n",
    "            logging.error(\"[Number Exception] number different than 2 or 3\")\n",
    "\n",
    "        return sentence + \" \" + generated_text.strip()\n",
    "\n",
    "\n",
    "    def auto_correct(self,sentence):\n",
    "\n",
    "        \"\"\" \n",
    "        Perform auto-correction using the N-gram language model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : str\n",
    "            The input sentence to be auto-corrected.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of tuples\n",
    "            A list of candidate words with their scores, sorted by score in descending order.\n",
    "        \"\"\"\n",
    "\n",
    "        probabilities = self.probabilities_bigram if self.ngram_size==2 else self.probabilities_trigram\n",
    "\n",
    "        text  = self.split_into_sentences(\"<s> \"*(self.ngram_size-1) +  sentence)\n",
    "        sentences = text.split(\"<stop>\")\n",
    "        sentences = [s.strip().lower() for s in sentences]\n",
    "        tokens = [s.split(\" \") for s in sentences][0]\n",
    "\n",
    "\n",
    "        # selecting the last token to base on\n",
    "        words = ['<unk>' if word not in self.unigram_counts else word for word in tokens]\n",
    "        auto_corrector = Auto_Corrector(self.unigram_counts)\n",
    "\n",
    "        for i in range(len(words)):\n",
    "\n",
    "            if words[i] != tokens[i] : # found an unkonwn word\n",
    "                surrounding_words = tokens[i-(self.ngram_size)+1:i]\n",
    "                pre_words = \"\"\n",
    "\n",
    "                for word in surrounding_words:\n",
    "                    pre_words+= word + \" \"\n",
    "\n",
    "                candidates = auto_corrector.candidates(tokens[i]) #bring the candidates\n",
    "                list_candidates = []\n",
    "\n",
    "                for j in range(len(candidates)):\n",
    "\n",
    "                    if candidates[j][0] != '<unk>':\n",
    "\n",
    "                        score = candidates[j][1]**(2) + probabilities[pre_words + candidates[j][0]] if probabilities.get(pre_words + candidates[j][0]) is not None else candidates[j][1]**(2)\n",
    "                        list_candidates.append((candidates[j][0],score))\n",
    "\n",
    "        return(sorted(list_candidates, key=lambda x: x[1]))\n",
    "\n",
    "\n",
    "    def save_configurations(self):\n",
    "\n",
    "        \"\"\" \n",
    "        Save the configurations of the N-gram language model to files.\n",
    "\n",
    "        This method saves the configurations of the model, including counts, probabilities, and other parameters, \n",
    "        to configuration files(config.ini + configuration.json).\n",
    "        \"\"\" \n",
    "        \n",
    "        configuration = {}\n",
    "        dictionary = {}\n",
    "\n",
    "        setup = configparser.ConfigParser()\n",
    "\n",
    "        dictionary[\"ngram_size\"] = self.ngram_size\n",
    "\n",
    "        dictionary[\"unigram_count\"] = self.unigram_counts\n",
    "        dictionary[\"bigram_count\"] = self.bigram_counts\n",
    "        dictionary[\"trigram_count\"] = self.trigram_counts\n",
    "\n",
    "        dictionary[\"probabilities_bigram\"] = self.probabilities_bigram \n",
    "        dictionary[\"probabilities_trigram\"] = self.probabilities_trigram  # Add this line\n",
    "\n",
    "        setup['settings'] = {\n",
    "            \"k\" : self.k,\n",
    "            \"alphabets\" : self.alphabets,\n",
    "            \"prefixes\" : self.prefixes,\n",
    "            \"suffixes\" : self.suffixes,\n",
    "            \"starters\" : self.starters,\n",
    "            \"acronyms\" : self.starters,\n",
    "            \"websites\" : self.websites,\n",
    "            \"digits\" : self.digits,\n",
    "            \"multiple_dots\" : self.multiple_dots,\n",
    "            \"characters\" : self.characters,\n",
    "            \"replacements\" : self.replacements,\n",
    "            \"lines_processed\" : self.lines_processed\n",
    "        }\n",
    "\n",
    "        configuration[\"dictionary\"] = dictionary\n",
    "        with open('config.ini', 'w') as configfile:\n",
    "            setup.write(configfile)\n",
    "\n",
    "        save_dict_to_json(configuration, \"configuration.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "model = NgramLanguageModel(ngram_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47961"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lines_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s> how': -4.937424477244247,\n",
       " 'how are': -3.034988894618542,\n",
       " 'are you': -1.9515964826892505,\n",
       " 'you ?': -4.155291844604722,\n",
       " '? </s>': -0.021870640597409487,\n",
       " '<s> btw': -7.512744329500963,\n",
       " 'btw thanks': -4.776947122604469,\n",
       " 'thanks for': -0.8627461830802949,\n",
       " 'for the': -1.6931693419110425,\n",
       " 'the rt': -5.483720762934675,\n",
       " 'rt .': -4.287381265303947,\n",
       " '. </s>': -0.3480631950291979,\n",
       " '<s> you': -3.8325038614856166,\n",
       " 'you gonna': -6.542530363754041,\n",
       " 'gonna be': -1.7126321365784125,\n",
       " 'be in': -3.5291803338267957,\n",
       " 'in dc': -5.797244494798235,\n",
       " 'dc anytime': -5.514187002212487,\n",
       " 'anytime soon': -3.147199794536901,\n",
       " 'soon ?': -3.5059757173040675,\n",
       " '<s> love': -5.282380625035937,\n",
       " 'love to': -2.894914021895187,\n",
       " 'to see': -3.4184375298332896,\n",
       " 'see you': -1.5901129404961984,\n",
       " 'you .': -3.2785781977283666,\n",
       " '<s> been': -7.246180662125708,\n",
       " 'been way': -6.287201776067501,\n",
       " 'way ,': -3.6537970589539697,\n",
       " ', way': -8.038363179092046,\n",
       " 'way too': -3.23409222803467,\n",
       " 'too long': -4.267085919550605,\n",
       " 'long .': -2.9041422563256276,\n",
       " '<s> when': -5.451058774453754,\n",
       " 'when you': -1.711340909756674,\n",
       " 'you meet': -7.352766761861639,\n",
       " 'meet someone': -4.839992779316149,\n",
       " 'someone special': -5.721322602309758,\n",
       " 'special .': -3.390146536291491,\n",
       " '. .': -1.3586573025737356,\n",
       " 'you ll': -4.4095112147859785,\n",
       " 'll know': -5.341999825105625,\n",
       " 'know .': -2.724729401941998,\n",
       " '<s> your': -6.0150745323049,\n",
       " 'your heart': -4.649925393815269,\n",
       " 'heart will': -4.810670637013371,\n",
       " 'will beat': -6.554713972177107,\n",
       " 'beat more': -4.942601450867581,\n",
       " 'more rapidly': -6.601439646852034,\n",
       " 'rapidly and': -4.435720651983864,\n",
       " 'and you': -4.003150598677148,\n",
       " 'll smile': -6.437289851581757,\n",
       " 'smile for': -4.46131516075844,\n",
       " 'for no': -6.680566343336245,\n",
       " 'no reason': -5.174963774180556,\n",
       " 'reason .': -2.8568147590589157,\n",
       " '<s> they': -5.294392420760679,\n",
       " 'they ve': -4.654307424658869,\n",
       " 've decided': -4.2058391849797285,\n",
       " 'decided its': -5.354482437901729,\n",
       " 'its more': -5.419883759962984,\n",
       " 'more fun': -5.101239297302772,\n",
       " 'fun if': -6.394732523817772,\n",
       " 'if i': -2.1170080067041366,\n",
       " 'i don': -3.602611926491044,\n",
       " 'don t': -0.11566735567762276,\n",
       " 't .': -3.987072451309197,\n",
       " '<s> so': -4.549741249301848,\n",
       " 'so tired': -4.733232360730388,\n",
       " 'tired d': -5.763575844458316,\n",
       " 'd played': -6.943418644089326,\n",
       " 'played <unk>': -4.410157136148496,\n",
       " '<unk> tag': -5.100047527097278,\n",
       " 'tag ran': -5.208620117604613,\n",
       " 'ran a': -4.647400144086163,\n",
       " 'a lot': -3.9508614102305066,\n",
       " 'lot d': -6.050737061295821,\n",
       " 'd <unk>': -3.4267143759233902,\n",
       " '<unk> going': -2.113765709354804,\n",
       " 'going to': -0.6159180161327966,\n",
       " 'to sleep': -5.260987215474756,\n",
       " 'sleep like': -5.338948298040795,\n",
       " 'like in': -5.273994689092104,\n",
       " 'in 5': -6.489975268939505,\n",
       " '5 minutes': -3.696470129365272,\n",
       " 'minutes words': -5.692731538359,\n",
       " 'words from': -4.406262966552448,\n",
       " 'from a': -3.242165887489488,\n",
       " 'a complete': -6.6748570912818375,\n",
       " 'complete stranger': -4.734145194140019,\n",
       " 'stranger !': -4.122030825658595,\n",
       " '! </s>': -0.008590665489928744,\n",
       " '<s> made': -7.66223127404939,\n",
       " 'made my': -2.465369483810168,\n",
       " 'my birthday': -4.894240430231029,\n",
       " 'birthday even': -6.239387642756711,\n",
       " 'even better': -3.9455365751101406,\n",
       " 'better </s>': -5.242775658923093,\n",
       " '<s> first': -6.937501686007835,\n",
       " 'first cubs': -6.694059530549741,\n",
       " 'cubs game': -5.214020573566212,\n",
       " 'game ever': -5.26493593068507,\n",
       " 'ever !': -2.7474369466496666,\n",
       " '<s> wrigley': -11.086590676308578,\n",
       " 'wrigley field': -4.453247536353355,\n",
       " 'field is': -4.725360493205281,\n",
       " 'is gorgeous': -8.934295929415372,\n",
       " 'gorgeous .': -4.285623665301447,\n",
       " '<s> this': -4.9566349034435895,\n",
       " 'this is': -2.429618688440025,\n",
       " 'is perfect': -6.458506624176648,\n",
       " 'perfect .': -2.7008389808788724,\n",
       " '<s> go': -5.833799006127631,\n",
       " 'go cubs': -6.7353367636123025,\n",
       " 'cubs go': -4.525836182348396,\n",
       " 'go !': -3.1026065751053378,\n",
       " '<s> i': -2.2793899007184457,\n",
       " 'i no': -7.642621010969573,\n",
       " 'no !': -3.981737821642583,\n",
       " 'i get': -4.522787070339182,\n",
       " 'get another': -5.713996467529147,\n",
       " 'another day': -3.110632728279435,\n",
       " 'day off': -4.440109871785727,\n",
       " 'off from': -5.073164726819192,\n",
       " 'from skool': -7.509020554897096,\n",
       " 'skool due': -5.147206615905855,\n",
       " 'due to': -1.574642406853652,\n",
       " 'to the': -2.850143749676901,\n",
       " 'the wonderful': -7.2261010294477925,\n",
       " 'wonderful snow': -5.598311941945621,\n",
       " 'snow and': -4.729762490012947,\n",
       " 'and this': -5.741516078668549,\n",
       " 'this wakes': -8.153041996420496,\n",
       " 'wakes me': -4.441597145359681,\n",
       " 'me up': -3.9975572524909513,\n",
       " 'up .': -2.3733393000442984,\n",
       " '<s> damn': -6.563833992907371,\n",
       " 'damn thing': -4.664873156868854,\n",
       " 'thing i': -2.805004774998928,\n",
       " 'i m': -1.9609040994771345,\n",
       " 'm coo': -7.984233313332105,\n",
       " 'coo .': -4.453247536353355,\n",
       " '<s> jus': -8.898205935541501,\n",
       " 'jus at': -5.33558453530398,\n",
       " 'at work': -3.9932610945101956,\n",
       " 'work hella': -6.936708303237205,\n",
       " 'hella tired': -4.552409463005369,\n",
       " 'tired r': -5.763575844458316,\n",
       " 'r u': -2.2035733362956744,\n",
       " 'u ever': -5.100990051434449,\n",
       " 'ever in': -4.228269234145538,\n",
       " 'in cali': -6.777379833411151,\n",
       " 'cali the': -5.219392021191338,\n",
       " 'the new': -4.552617150884465,\n",
       " 'new <unk>': -3.2512860690189553,\n",
       " '<unk> commercial': -3.1626601569039474,\n",
       " 'commercial .': -3.279050907454768,\n",
       " '<s> hehe': -8.610801371069854,\n",
       " 'hehe love': -5.240593854223185,\n",
       " 'love at': -6.135586492666432,\n",
       " 'at first': -5.657689953370655,\n",
       " 'first sight': -6.694059530549741,\n",
       " 'sight we': -5.1586569041721235,\n",
       " 'we need': -3.5281489107569115,\n",
       " 'need to': -1.0625095762522168,\n",
       " 'to reconnect': -8.578008219180916,\n",
       " 'reconnect this': -5.117993812416755,\n",
       " 'this week': -3.063064925698647,\n",
       " 'week i': -4.176971515122698,\n",
       " 'i always': -5.606704660957309,\n",
       " 'always wonder': -6.593546239272387,\n",
       " 'wonder how': -2.848655281533678,\n",
       " 'how the': -4.121388387813469,\n",
       " 'the guys': -7.2261010294477925,\n",
       " 'guys on': -4.222750466806971,\n",
       " 'on the': -1.7997126190253572,\n",
       " 'the auctions': -9.85592205894354,\n",
       " 'auctions shows': -5.117993812416755,\n",
       " 'shows learned': -5.514187002212487,\n",
       " 'learned to': -3.5987016716789784,\n",
       " 'to talk': -5.336013014390542,\n",
       " 'talk so': -5.097899499956229,\n",
       " 'so fast': -5.5277707334938295,\n",
       " 'fast !': -2.8772952932763225,\n",
       " '<s> all': -5.823490167861598,\n",
       " 'all i': -3.41858778352594,\n",
       " 'i hear': -5.763249161520742,\n",
       " 'hear is': -4.997638689076641,\n",
       " 'is <unk>': -3.7512338553659266,\n",
       " '<unk> .': 2.626313605400532,\n",
       " '<s> <unk>': -3.33096768519132,\n",
       " '<unk> what': -1.177976166015611,\n",
       " 'what a': -2.82490740318178,\n",
       " 'a catch': -8.749935896219476,\n",
       " 'catch such': -5.52213395864621,\n",
       " 'such a': -1.004043326256693,\n",
       " 'a great': -3.257734720843989,\n",
       " 'great picture': -6.764464979967684,\n",
       " 'picture !': -3.2558270007635914,\n",
       " '<s> the': -4.139986040246005,\n",
       " 'the green': -8.072447641249592,\n",
       " 'green shirt': -4.797680128807676,\n",
       " 'shirt totally': -5.4567164349219395,\n",
       " 'totally brings': -5.731994604897382,\n",
       " 'brings out': -4.219458847230574,\n",
       " 'out your': -4.664464084727515,\n",
       " 'your eyes': -5.180347844238731,\n",
       " 'eyes !': -4.28683178487715,\n",
       " '<s> desk': -11.086590676308578,\n",
       " 'desk put': -5.27664864274067,\n",
       " 'put together': -4.972647043739957,\n",
       " 'together ,': -3.608815936012988,\n",
       " ', room': -9.639848763335651,\n",
       " 'room all': -5.869660442730485,\n",
       " 'all set': -7.908558227941766,\n",
       " 'set up': -2.434727624417621,\n",
       " '<s> oh': -5.153715385660325,\n",
       " 'oh boy': -4.523897532452028,\n",
       " 'boy ,': -3.240032614789228,\n",
       " ', oh': -6.513870190141545,\n",
       " 'boy i': -4.336981009562643,\n",
       " 'm doing': -4.592652984732997,\n",
       " 'doing it': -3.1312057429860016,\n",
       " 'it !': -2.872895983821865,\n",
       " '<s> beauty': -11.086590676308578,\n",
       " 'beauty brainstorming': -5.31144859513819,\n",
       " 'brainstorming in': -5.12390504320168,\n",
       " 'in the': -1.572038524903585,\n",
       " 'the <unk>': -2.7766208945204043,\n",
       " '<unk> office': -3.31657310940333,\n",
       " 'office with': -4.994485687879025,\n",
       " 'with and': -4.716481756275981,\n",
       " 'and sally': -9.099206345948692,\n",
       " 'sally walker': -5.117993812416755,\n",
       " 'walker !': -5.224734770450013,\n",
       " '<s> looking': -5.966583122391611,\n",
       " 'looking for': -1.4254433773145097,\n",
       " 'for a': -2.5855393633314843,\n",
       " 'a new': -4.07274591538164,\n",
       " 'new band': -5.7343613689236035,\n",
       " 'band to': -5.696062986954392,\n",
       " 'to blog': -8.981813575870717,\n",
       " 'blog for': -4.8841202150238505,\n",
       " 'the month': -7.157155744151337,\n",
       " 'month .': -2.3646321469225158,\n",
       " '<s> anyone': -6.471470159467319,\n",
       " 'anyone interested': -4.510420581145404,\n",
       " 'interested ?': -3.2596706461920952,\n",
       " '<s> packing': -9.01585024608148,\n",
       " 'packing for': -3.6285635421267486,\n",
       " 'a quick': -6.882352325766047,\n",
       " 'quick move': -5.443959532746799,\n",
       " 'move down': -5.682670079096841,\n",
       " 'down the': -2.718438326180532,\n",
       " 'the street': -6.729943485749433,\n",
       " 'street .': -2.5784661726490214,\n",
       " '<s> if': -4.630380730945527,\n",
       " 'if only': -4.30698642796592,\n",
       " 'only i': -4.745433860313838,\n",
       " 'i had': -4.542588717291741,\n",
       " 'had some': -4.242327591819436,\n",
       " 'some movers': -7.22182136062562,\n",
       " 'movers .': -5.117993812416755,\n",
       " '<s> ford': -9.994600928400963,\n",
       " 'ford focus': -4.536550379232197,\n",
       " 'focus hatchback': -4.707556132745382,\n",
       " 'hatchback ?': -5.112047431096548,\n",
       " '<s> rt': -4.142847245238445,\n",
       " 'rt according': -6.885453711037487,\n",
       " 'according to': -2.066815309763069,\n",
       " 'the national': -7.562287796469579,\n",
       " 'national retail': -5.506176385418376,\n",
       " 'retail federation': -5.164333254771421,\n",
       " 'federation 16': -5.117993812416755,\n",
       " '16 .': -3.3339418978491175,\n",
       " '. 3': -8.56307097925225,\n",
       " '3 billion': -6.090745991367329,\n",
       " 'billion was': -5.181171504091313,\n",
       " 'was spent': -7.153398042904435,\n",
       " 'spent on': -4.0168996134978885,\n",
       " 'on mothersday': -8.648337827110065,\n",
       " 'mothersday last': -5.141431927571171,\n",
       " 'last year': -3.050692367120831,\n",
       " 'year !': -2.4411199895710967,\n",
       " 'the tragedy': -9.167737667725724,\n",
       " 'tragedy of': -5.175590198091908,\n",
       " 'of life': -5.2775386513518825,\n",
       " 'life is': -2.4195684900329093,\n",
       " 'is not': -3.740184629646224,\n",
       " 'not that': -4.407402472631474,\n",
       " 'that it': -4.76973140728575,\n",
       " 'it ends': -7.386165341217967,\n",
       " 'ends so': -5.286715672945638,\n",
       " 'so soon': -6.3741173452956295,\n",
       " 'soon ,': -3.1613067134786763,\n",
       " ', but': -2.8352452200406995,\n",
       " 'but that': -4.210272638110296,\n",
       " 'that we': -4.5344601038454195,\n",
       " 'we wait': -7.474501237050969,\n",
       " 'wait so': -6.574385156518677,\n",
       " 'so long': -4.989071683609583,\n",
       " 'long to': -4.3583352147314045,\n",
       " 'to begin': -7.1942086618498085,\n",
       " 'begin it': -5.373029823573578,\n",
       " 'it .': -2.5053462698939004,\n",
       " '<s> w': -8.456769646812832,\n",
       " 'w .': -3.075947989114235,\n",
       " '. m': -6.739359910217592,\n",
       " 'm .': -3.5632478048085168,\n",
       " '. lewis': -10.168520850508395,\n",
       " 'lewis more': -5.164333254771421,\n",
       " 'more skating': -7.28962403806985,\n",
       " 'skating !': -4.464763757369317,\n",
       " '<s> come': -5.721216304252926,\n",
       " 'come by': -3.7782137784041203,\n",
       " 'by the': -2.042484988016388,\n",
       " 'the check': -7.918534688750209,\n",
       " 'check out': -1.1740088360727772,\n",
       " 'out a': -4.2591378172998935,\n",
       " 'a movie': -5.810221335289303,\n",
       " 'movie ,': -3.848020337366496,\n",
       " ', eat': -7.8563743456417034,\n",
       " 'eat a': -3.294249438097362,\n",
       " 'great dinner': -6.0738084607201905,\n",
       " 'dinner and': -3.9893845333150564,\n",
       " 'and top': -9.099206345948692,\n",
       " 'top it': -4.397093357418348,\n",
       " 'it off': -5.73912017685418,\n",
       " 'off with': -4.4677855246317195,\n",
       " 'with great': -5.909707708813954,\n",
       " 'great times': -6.764464979967684,\n",
       " 'times at': -5.192597471782856,\n",
       " 'at the': -1.6760423464648595,\n",
       " 'the ice': -7.78518162871644,\n",
       " 'ice rink': -4.849656491037292,\n",
       " 'rink .': -5.1297815365774975,\n",
       " '<s> watch': -7.540907272195173,\n",
       " 'watch your': -4.649425799842853,\n",
       " 'your mailbox': -8.166629661981204,\n",
       " 'mailbox !': -5.117993812416755,\n",
       " '<unk> the': 0.4545608628145232,\n",
       " 'the day': -4.533105288519446,\n",
       " 'day .': -2.1717998078332297,\n",
       " '<s> good': -5.095101377031687,\n",
       " 'good questions': -7.688382785963678,\n",
       " 'questions .': -2.938270879425793,\n",
       " 'rt your': -5.636250732061972,\n",
       " 'your brand': -6.5651440777376,\n",
       " 'brand will': -5.431037786859031,\n",
       " 'will be': -1.3503605159811896,\n",
       " 'be judged': -7.198009621703669,\n",
       " 'judged based': -5.12390504320168,\n",
       " 'based on': -2.1728506753365666,\n",
       " 'on its': -6.354703564636106,\n",
       " 'its website': -6.798724670428293,\n",
       " 'website .': -2.534936462690226,\n",
       " '<s> is': -5.156343438998096,\n",
       " 'is your': -4.40084510067808,\n",
       " 'your website': -5.467863347189002,\n",
       " 'website a': -5.616483027375429,\n",
       " 'a good': -3.559164959510216,\n",
       " 'good brand': -7.688382785963678,\n",
       " 'brand ambassador': -5.431037786859031,\n",
       " 'ambassador ?': -5.1297815365774975,\n",
       " '<s> .': -5.061035651478176,\n",
       " '<s> don': -5.444016739789358,\n",
       " 't care': -4.452366805267785,\n",
       " 'care what': -3.4808068228490647,\n",
       " 'what others': -6.798203637701779,\n",
       " 'others think': -3.8543868421704235,\n",
       " 'think of': -2.9210786743624535,\n",
       " 'of you': -4.010039084583886,\n",
       " 'you ,': -4.053514087513925,\n",
       " ', and': -3.0164675031002703,\n",
       " 'you will': -4.621191870061213,\n",
       " 'will save': -6.554713972177107,\n",
       " 'save yourself': -4.8765635991736795,\n",
       " 'yourself a': -4.198716565510428,\n",
       " 'lot of': -1.1930760215749112,\n",
       " 'of mental': -8.905437603499871,\n",
       " 'mental energy': -5.203190338287276,\n",
       " 'energy that': -4.3390480389514146,\n",
       " 'that instead': -8.651805435354039,\n",
       " 'instead can': -5.590950035835504,\n",
       " 'can be': -3.226259456418668,\n",
       " 'be used': -5.660178340115538,\n",
       " 'used to': -1.4351699807670708,\n",
       " 'to push': -7.886523549394584,\n",
       " 'push you': -4.525836182348396,\n",
       " 'you towards': -8.331517444181122,\n",
       " 'towards success': -5.235335389143063,\n",
       " 'success .': -2.3409724341837284,\n",
       " 'this ron': -8.153041996420496,\n",
       " 'ron artest': -3.3392612725473394,\n",
       " 'artest interview': -5.1586569041721235,\n",
       " 'interview .': -3.519329064728609,\n",
       " 'is it': -3.6711954209683904,\n",
       " 'it possible': -7.204176507767624,\n",
       " 'possible to': -3.13740352438507,\n",
       " 'to die': -6.544019393894426,\n",
       " 'die from': -4.385633080434105,\n",
       " 'from laughter': -6.820836163679279,\n",
       " 'laughter ?': -5.152948148587133,\n",
       " '<s> linda': -10.398406285090763,\n",
       " 'linda !': -5.12390504320168,\n",
       " '<s> just': -4.604286020740908,\n",
       " 'just looked': -6.125338694822642,\n",
       " 'looked at': -3.238308424408077,\n",
       " 'at my': -4.020656315458795,\n",
       " 'my <unk>': -3.3211816821078886,\n",
       " '<unk> i': 0.6426065264030383,\n",
       " 'i have': -3.3655079576839433,\n",
       " 'have to': -2.120991892278256,\n",
       " 'to hustle': -9.669997967088532,\n",
       " 'hustle back': -5.1356236984296695,\n",
       " 'back to': -1.8797167371349885,\n",
       " 'to chula': -9.669997967088532,\n",
       " 'chula for': -5.117993812416755,\n",
       " 'for p': -8.974200605810207,\n",
       " 'p .': -1.8380324545774256,\n",
       " '. meetings': -9.764715493818596,\n",
       " 'meetings ,': -3.680209241683199,\n",
       " ', so': -4.37674825488867,\n",
       " 'so no': -6.086851332762477,\n",
       " 'no time': -4.912830074983271,\n",
       " 'time 4': -5.65994591130544,\n",
       " '4 lunch': -6.533486581804959,\n",
       " 'lunch .': -2.6726591890412594,\n",
       " '<s> do': -5.7882238060353775,\n",
       " 'do u': -3.565261489718989,\n",
       " 'u meet': -6.801659280098054,\n",
       " 'meet every': -5.931982527223765,\n",
       " 'every fri': -6.292064066566691,\n",
       " 'fri ?': -4.487405806874092,\n",
       " '<s> bum': -10.398406285090763,\n",
       " 'bum squad': -5.175590198091908,\n",
       " 'squad lets': -5.1356236984296695,\n",
       " 'lets get': -3.067892044154785,\n",
       " 'get it': -3.1032476074691475,\n",
       " 'rt shout': -6.885453711037487,\n",
       " 'shout that': -5.62366000582603,\n",
       " 'that ninja': -8.651805435354039,\n",
       " 'ninja out': -5.175590198091908,\n",
       " 'out for': -3.835419508073311,\n",
       " 'for winning': -6.680566343336245,\n",
       " 'winning i': -4.755775141528983,\n",
       " 'i love': -3.2700591147460716,\n",
       " 'love you': -2.0398789209748256,\n",
       " 'and i': -2.6762005070215,\n",
       " 'm so': -3.2755954911616243,\n",
       " 'so proud': -4.611908358876171,\n",
       " 'proud of': -1.47200774413302,\n",
       " '<s> from': -7.485352860763682,\n",
       " 'from sitting': -7.509020554897096,\n",
       " 'sitting on': -3.224534112199184,\n",
       " 'on those': -6.710950456916736,\n",
       " 'those stairs': -5.683122763750867,\n",
       " 'stairs on': -5.181171504091313,\n",
       " 'the x': -7.78518162871644,\n",
       " 'x factor': -3.721404642964435,\n",
       " 'factor ,': -4.51500594706946,\n",
       " ', to': -5.717777402253985,\n",
       " 'to now': -8.068512382844927,\n",
       " 'now .': -1.7156879781717356,\n",
       " 'you boys': -8.735322800870922,\n",
       " 'boys are': -4.542340060746309,\n",
       " 'are my': -4.96959056664199,\n",
       " 'my inspiration': -7.599185038775086,\n",
       " 'inspiration .': -3.0467083348112496,\n",
       " '<s> </s>': -4.352470042356751,\n",
       " '<s> xx': -8.151575850661409,\n",
       " 'xx maybe': -5.251028550039501,\n",
       " 'maybe some': -5.428013678323548,\n",
       " 'some other': -5.4383469429316715,\n",
       " 'other time': -5.613000996592274,\n",
       " 'time i': -2.9646219368817155,\n",
       " 'i can': -3.292722653282508,\n",
       " 'can t': -1.151030975227904,\n",
       " 't slow': -7.743401297801601,\n",
       " 'slow down': -3.82084400111423,\n",
       " 'down ,': -3.2572860594513635,\n",
       " ', right': -5.345598874979444,\n",
       " 'right across': -5.929509618067665,\n",
       " 'across that': -5.473476369691145,\n",
       " 'that state': -7.559815687446422,\n",
       " 'state line': -5.6860351595008085,\n",
       " 'line right': -5.050206755782381,\n",
       " 'right about': -3.8955207927811744,\n",
       " 'about now': -4.7744092828488025,\n",
       " 'now <unk>': -4.392318143025632,\n",
       " '<unk> leak': -5.100047527097278,\n",
       " 'leak !': -5.117993812416755,\n",
       " 'love reading': -7.048887685692221,\n",
       " 'reading your': -3.3870806480022373,\n",
       " 'your magazine': -8.166629661981204,\n",
       " 'magazine it': -5.296682367298582,\n",
       " 'it always': -6.598797305580152,\n",
       " 'always cheers': -5.905361848054571,\n",
       " 'cheers me': -4.652158206067394,\n",
       " 'up tables': -7.81875281867845,\n",
       " 'tables are': -4.4704725129543075,\n",
       " 'are all': -4.434245037471185,\n",
       " 'all sold': -7.22037383672395,\n",
       " 'sold out': -2.199905048485454,\n",
       " '<unk> masquerade': -5.100047527097278,\n",
       " 'masquerade ball': -5.112047431096548,\n",
       " 'ball .': -3.4538520884221673,\n",
       " '<s> make': -6.906734761461068,\n",
       " 'make one': -5.3958660117185815,\n",
       " 'one up': -5.943773329773423,\n",
       " 'up !': -2.9765947636636003,\n",
       " '<s> it': -3.9066112949662464,\n",
       " 'it might': -6.28888461066937,\n",
       " 'might help': -6.024741316188914,\n",
       " 'help you': -3.073128586819183,\n",
       " 'you feel': -5.54143316402045,\n",
       " 'feel better': -3.0324931071020598,\n",
       " 'better .': -2.354761901980795,\n",
       " '<s> alternative': -10.398406285090763,\n",
       " 'alternative just': -5.175590198091908,\n",
       " 'just scream': -8.062726065015973,\n",
       " 'scream nonsense': -5.214020573566212,\n",
       " 'nonsense at': -5.164333254771421,\n",
       " 'the dumb': -7.918534688750209,\n",
       " 'dumb machine': -5.386718042041821,\n",
       " 'machine .': -4.568020957668656,\n",
       " '<s> ya': -8.205613847973883,\n",
       " 'ya ik': -6.076074114668435,\n",
       " 'ik and': -5.1586569041721235,\n",
       " 'i never': -5.458804455727787,\n",
       " 'never asked': -6.760460581062212,\n",
       " 'asked him': -4.1896925256396775,\n",
       " 'him to': -3.36208328506586,\n",
       " 'to follow': -5.158051031147431,\n",
       " 'follow me': -1.4499197555443393,\n",
       " 'me i': -3.9044776682702773,\n",
       " 'i only': -6.344145536724718,\n",
       " 'only mentioned': -6.933818601080916,\n",
       " 'mentioned him': -5.224734770450013,\n",
       " 'him once': -6.530603364445854,\n",
       " 'once in': -3.3093145717790335,\n",
       " 'in one': -5.391918227370613,\n",
       " 'one of': -1.7470367253106152,\n",
       " 'of my': -3.0718145322345056,\n",
       " 'my tweets': -6.135406825011456,\n",
       " 'tweets i': -3.915355534823622,\n",
       " 'i didnt': -6.895990926089482,\n",
       " 'didnt do': -4.257801589774251,\n",
       " 'do anything': -4.391739221600884,\n",
       " 'anything else': -3.679520107436373,\n",
       " 'else i': -4.8556315373240135,\n",
       " 'i will': -4.0979208440119175,\n",
       " 'will 3': -6.958519328866908,\n",
       " '3 great': -5.58125015503134,\n",
       " 'great talking': -6.764464979967684,\n",
       " 'talking to': -2.138956174147863,\n",
       " 'to you': -4.1745761124290395,\n",
       " 'you guys': -4.105532811641211,\n",
       " 'guys tonight': -5.03229429710874,\n",
       " 'tonight !': -1.8069294827209816,\n",
       " 'looking forward': -1.380240495251479,\n",
       " 'forward to': -0.6501735097725205,\n",
       " 'to your': -4.926271903654386,\n",
       " 'your piece': -7.074639914073589,\n",
       " 'piece next': -5.417946881230763,\n",
       " 'next week': -2.1867762765982715,\n",
       " 'week jon': -6.652760820361422,\n",
       " 'jon .': -5.186721831932668,\n",
       " '<s> small': -9.149203306115249,\n",
       " 'small market': -5.545602787176848,\n",
       " 'market baseball': -5.443959532746799,\n",
       " 'baseball .': -3.4354359551912768,\n",
       " ', know': -8.951664372117836,\n",
       " '<s> for': -6.085839048620948,\n",
       " 'the 99': -8.254436474699935,\n",
       " '99 .': -3.25525952027462,\n",
       " '<s> sing': -9.70774976584327,\n",
       " 'sing it': -3.7483057534382627,\n",
       " 'it comes': -5.701394088510216,\n",
       " 'comes on': -4.313890627893691,\n",
       " 'on tonight': -6.09256986543882,\n",
       " '<s> not': -5.379480411559704,\n",
       " 'not tomorrow': -7.206078296425591,\n",
       " 'tomorrow !': -2.17472821293815,\n",
       " '<s> maybe': -6.22892963658767,\n",
       " 'maybe ?': -3.927813328774286,\n",
       " 'just seems': -6.683885154550663,\n",
       " 'seems they': -5.658792013157766,\n",
       " 'they thought': -5.876672915969866,\n",
       " 'thought up': -6.161061093850946,\n",
       " 'up that': -5.42989919879703,\n",
       " 'that idea': -6.86833101766009,\n",
       " 'idea over': -5.897235465874264,\n",
       " 'over sunday': -6.697730741398704,\n",
       " 'sunday brunch': -4.7464332400449125,\n",
       " 'brunch and': -4.547150997925247,\n",
       " 'and thought': -7.161818975755363,\n",
       " 'thought it': -2.559823278306049,\n",
       " 'it was': -2.8972598830213707,\n",
       " 'was swell': -7.841582434122252,\n",
       " 'swell .': -4.453247536353355,\n",
       " '<s> thanks': -4.055995860416704,\n",
       " 'the ff': -6.43156265668435,\n",
       " 'ff !': -2.975799016741137,\n",
       " '<s> awfully': -11.086590676308578,\n",
       " 'awfully good': -4.441597145359681,\n",
       " 'good company': -7.688382785963678,\n",
       " 'company to': -3.8802665806011976,\n",
       " 'to be': -2.8224237202044873,\n",
       " 'in .': -4.685118486963402,\n",
       " 'the longer': -8.254436474699935,\n",
       " 'longer we': -5.4223295853578355,\n",
       " 'we live': -5.463919313476583,\n",
       " 'live the': -4.217857849776746,\n",
       " 'the more': -6.15205645039274,\n",
       " 'more we': -5.910783127604541,\n",
       " 'we find': -6.7838447178034755,\n",
       " 'find we': -6.215933951763339,\n",
       " 'we are': -2.4105531302953285,\n",
       " 'are like': -5.151828828279511,\n",
       " 'like other': -7.215631327370035,\n",
       " 'other persons': -6.30118538781009,\n",
       " 'persons .': -5.141431927571171,\n",
       " '<unk> <unk>': 1.8598022104032186,\n",
       " '<unk> holmes': -5.100047527097278,\n",
       " 'holmes made': -5.117993812416755,\n",
       " 'my list': -6.620434356455602,\n",
       " 'list for': -3.1795445310798742,\n",
       " 'for top': -8.974200605810207,\n",
       " 'top 99': -5.775934267883658,\n",
       " '99 women': -5.3259999505017195,\n",
       " 'women .': -3.995525738478963,\n",
       " '<s> nice': -6.414317191731365,\n",
       " 'nice i': -5.6965758060362806,\n",
       " 'i watched': -6.79595756773291,\n",
       " 'watched the': -3.536088999497814,\n",
       " 'the whole': -5.603051677602706,\n",
       " 'whole series': -5.788141823273774,\n",
       " 'series ,': -3.263499574559534,\n",
       " ', loved': -8.261007852870343,\n",
       " 'loved julia': -5.738391147000197,\n",
       " 'julia and': -5.175590198091908,\n",
       " 'and her': -6.543438384277447,\n",
       " 'her mom': -6.114947174308445,\n",
       " 'mom erica': -6.036641401880127,\n",
       " 'erica was': -5.12390504320168,\n",
       " 'was such': -5.9041950639289205,\n",
       " 'a badass': -8.749935896219476,\n",
       " 'badass gop': -5.1356236984296695,\n",
       " 'gop line': -5.261355486448019,\n",
       " 'line on': -5.050206755782381,\n",
       " 'on obama': -7.269496916644757,\n",
       " 'obama gay': -5.564747990391496,\n",
       " 'gay marriage': -2.9638815045473095,\n",
       " 'marriage stance': -5.349791337681868,\n",
       " 'stance seems': -5.12390504320168,\n",
       " 'seems to': -2.171931798145832,\n",
       " 'be that': -5.996365107137324,\n",
       " 'that he': -4.76973140728575,\n",
       " 'he flip': -7.411029691704183,\n",
       " 'flip flopped': -5.208620117604613,\n",
       " 'flopped .': -5.117993812416755,\n",
       " '<s> really': -6.607792284190907,\n",
       " 'really want': -3.4091349473419954,\n",
       " 'want to': -0.7529346517052269,\n",
       " 'to use': -5.536654853987737,\n",
       " 'use that': -3.730207565331529,\n",
       " 'that with': -6.46342069458696,\n",
       " 'with romney': -7.515157580070099,\n",
       " 'romney as': -5.359151634412829,\n",
       " 'as your': -6.230213276536077,\n",
       " 'your presidential': -8.166629661981204,\n",
       " 'presidential candidate': -3.7854923443061113,\n",
       " 'candidate ?': -5.1922415235974855,\n",
       " 'i know': -3.859516619128926,\n",
       " 'know ,': -3.2527373815403537,\n",
       " ', i': -2.563889261657385,\n",
       " '<s> then': -6.377952854138099,\n",
       " 'then you': -3.462546951908634,\n",
       " 'you kick': -9.423507192088739,\n",
       " 'kick yourself': -5.404682328076217,\n",
       " 'yourself when': -4.708212401846417,\n",
       " 'when the': -3.24270843105548,\n",
       " 'the fight': -7.380132753704816,\n",
       " 'fight goes': -5.537840882255108,\n",
       " 'goes <unk>': -4.604073239046777,\n",
       " '<s> but': -4.920652947251305,\n",
       " 'but if': -4.185586121575472,\n",
       " 'if the': -3.5533800287601442,\n",
       " 'the upset': -9.167737667725724,\n",
       " 'upset does': -5.3163226117082,\n",
       " 'does happen': -6.235516695155008,\n",
       " 'happen ,': -3.507678246187314,\n",
       " ', wow': -7.569108333108552,\n",
       " 'wow .': -1.8306501309344951,\n",
       " '<s> nothing': -6.619090562776027,\n",
       " 'nothing like': -3.1768662188697965,\n",
       " 'like it': -3.1951778964173716,\n",
       " '<s> no': -4.929003552132568,\n",
       " 'no stress': -6.376608288746901,\n",
       " 'stress balls': -5.281694825926804,\n",
       " 'balls or': -5.224734770450013,\n",
       " 'or keg': -7.386182488463335,\n",
       " 'keg and': -5.1356236984296695,\n",
       " 'and different': -8.411021954730877,\n",
       " 'different crew': -5.712555757801136,\n",
       " 'crew but': -5.363799130810722,\n",
       " 'but these': -6.797461982218655,\n",
       " 'these guys': -3.6620232829008073,\n",
       " 'guys know': -4.809649623330444,\n",
       " 'know how': -2.9019192888917758,\n",
       " 'how to': -2.578676320919907,\n",
       " 'to party': -7.481613226321454,\n",
       " 'party william': -6.089628436984258,\n",
       " 'william davis': -5.208620117604613,\n",
       " 'davis attorney': -5.214020573566212,\n",
       " 'attorney says': -5.141431927571171,\n",
       " 'says client': -5.899951604111448,\n",
       " 'client will': -5.240593854223185,\n",
       " 'will plead': -7.646703720084724,\n",
       " 'plead insanity': -5.112047431096548,\n",
       " 'insanity .': -4.066667156264508,\n",
       " '<s> he': -5.143271699185308,\n",
       " 'he faces': -7.411029691704183,\n",
       " 'faces first': -5.203190338287276,\n",
       " 'first degree': -6.005875139331925,\n",
       " 'degree murder': -4.5312076299735216,\n",
       " 'murder charge': -5.181171504091313,\n",
       " 'charge in': -5.235335389143063,\n",
       " 'in woman': -8.965764574178229,\n",
       " 'woman s': -3.198395038518829,\n",
       " 's death': -6.717714114903249,\n",
       " 'death <unk>': -5.465131513822285,\n",
       " '<unk> ga': -4.411863135879462,\n",
       " 'ga i': -5.197730915435424,\n",
       " 'always considered': -6.593546239272387,\n",
       " 'considered myself': -5.1922415235974855,\n",
       " 'myself a': -4.097307445306724,\n",
       " 'a liberal': -8.749935896219476,\n",
       " 'liberal until': -5.169977566194647,\n",
       " 'until i': -2.450894969381298,\n",
       " 'i saw': -5.398187185960552,\n",
       " 'saw the': -2.871287252004017,\n",
       " 'the liberal': -8.763932311035925,\n",
       " 'liberal machine': -5.169977566194647,\n",
       " 'machine in': -5.256205348886472,\n",
       " 'in action': -6.489975268939505,\n",
       " 'action .': -2.928893022837493,\n",
       " 'was ugly': -6.749592686214635,\n",
       " 'ugly .': -3.398197165110649,\n",
       " '<s> weird': -8.323327480153123,\n",
       " 'weird thought': -5.568533436104987,\n",
       " 'thought we': -4.55957550960734,\n",
       " 'we got': -4.434728273940663,\n",
       " 'got to': -2.700675088904653,\n",
       " 'to witness': -9.669997967088532,\n",
       " 'witness the': -5.117993812416755,\n",
       " 'the change': -7.918534688750209,\n",
       " 'change of': -4.8786404517451185,\n",
       " 'of a': -3.298580473711246,\n",
       " 'a <unk>': -3.000748908014285,\n",
       " '<unk> ,': 1.815607162294486,\n",
       " ', the': -3.9003742616539174,\n",
       " 'the next': -5.103612988565842,\n",
       " 'next change': -6.676746721014098,\n",
       " 'change is': -4.8786404517451185,\n",
       " 'is 40': -7.842306181507755,\n",
       " '40 generations': -5.448229941081336,\n",
       " 'generations away': -5.117993812416755,\n",
       " 'away .': -2.401433574024401,\n",
       " '<s> imagine': -8.323327480153123,\n",
       " 'imagine what': -3.785232457798216,\n",
       " 'what the': -3.680488963275016,\n",
       " 'the differences': -9.167737667725724,\n",
       " 'differences will': -5.12390504320168,\n",
       " 'be !': -5.5912330548190825,\n",
       " '<s> got': -6.369064696789688,\n",
       " 'got a': -2.111649026500838,\n",
       " 'good one': -4.232284762835074,\n",
       " 'one ?': -4.259002077065673,\n",
       " 'love chris': -7.737072076910037,\n",
       " 'chris brown': -2.734837883943689,\n",
       " 'brown wit': -5.386718042041821,\n",
       " 'wit them': -4.781128255091076,\n",
       " 'them sexy': -6.8323807015190425,\n",
       " 'sexy ass': -4.776947122604469,\n",
       " 'ass lips': -6.082874240607232,\n",
       " 'lips its': -5.2300491263703535,\n",
       " 'its sounds': -6.110540279210477,\n",
       " 'sounds good': -2.609371268804916,\n",
       " 'good how': -6.596393038056061,\n",
       " 'how un': -7.443999646232318,\n",
       " 'un ?': -5.1922415235974855,\n",
       " '<s> fortunate': -10.398406285090763,\n",
       " 'fortunate that': -5.147206615905855,\n",
       " 'that those': -7.272964524888728,\n",
       " 'those days': -4.182922414201604,\n",
       " 'days when': -4.510420581145404,\n",
       " 'when every': -6.821378707245271,\n",
       " 'every status': -5.603879675348875,\n",
       " 'status update': -4.243594787396363,\n",
       " 'update was': -5.386718042041821,\n",
       " 'was a': -2.5481781069101146,\n",
       " 'a song': -5.836882471892396,\n",
       " 'song lyrics': -6.031898347478756,\n",
       " 'lyrics were': -5.224734770450013,\n",
       " 'were also': -5.816088960367519,\n",
       " 'also the': -4.649425799842853,\n",
       " 'the days': -7.300154097272294,\n",
       " 'when i': -1.6672822143224577,\n",
       " 'i first': -8.047531334042704,\n",
       " 'first discovered': -6.694059530549741,\n",
       " 'discovered new': -5.219392021191338,\n",
       " 'new wave': -5.7343613689236035,\n",
       " 'wave .': -4.536550379232197,\n",
       " 'had a': -1.3486699385302514,\n",
       " 'a bomb': -8.346130539529677,\n",
       " 'bomb ass': -4.552409463005369,\n",
       " 'ass day': -4.990884492699616,\n",
       " 'day chillin': -7.60862995116572,\n",
       " 'chillin with': -3.4465747086764056,\n",
       " 'with friends': -5.077363398093809,\n",
       " 'friends .': -2.1848516165302025,\n",
       " '<s> working': -7.312124126338747,\n",
       " 'working on': -1.6232770830510437,\n",
       " 'on music': -7.96015343589225,\n",
       " 'music for': -4.710536689651942,\n",
       " 'for holiday': -8.28601621459239,\n",
       " 'holiday show': -4.801775641760818,\n",
       " 'show on': -3.5717521682045974,\n",
       " 'the 23': -9.167737667725724,\n",
       " '23 in': -5.224734770450013,\n",
       " 'in santa': -7.586923663712919,\n",
       " 'santa barbara': -4.132745022542397,\n",
       " 'barbara !': -5.1586569041721235,\n",
       " '<s> open': -8.100308858566105,\n",
       " 'open bar': -4.389161797392431,\n",
       " 'bar !': -3.340695546179964,\n",
       " '<s> me': -6.2924379985745045,\n",
       " 'me ,': -3.200336812916955,\n",
       " ', tim': -8.547859015428035,\n",
       " 'tim from': -5.245824812429194,\n",
       " 'from palin': -7.509020554897096,\n",
       " 'palin white': -5.152948148587133,\n",
       " 'white t': -4.977488304124644,\n",
       " 't s': -6.494198318826086,\n",
       " 's and': -5.4658432867114985,\n",
       " 'and jr': -9.099206345948692,\n",
       " 'jr <unk>': -5.197730915435424,\n",
       " '<unk> from': -0.6100770826814521,\n",
       " 'from <unk>': -2.933901371469175,\n",
       " '<unk> !': 1.7816382016517944,\n",
       " '<s> hey': -5.406147769624562,\n",
       " 'hey nate': -6.4893403460330665,\n",
       " 'nate !': -4.481793174976831,\n",
       " 'for dropping': -8.28601621459239,\n",
       " 'dropping by': -4.509546524217608,\n",
       " 'by yesterday': -6.559340369903686,\n",
       " 'yesterday .': -2.1047534390819465,\n",
       " 'how was': -3.6925173302898413,\n",
       " 'was your': -4.240344618577355,\n",
       " 'your meal': -8.166629661981204,\n",
       " 'meal ?': -4.138059378462738,\n",
       " '<s> ff': -7.695010347709472,\n",
       " 'ff literary': -4.9174356550190685,\n",
       " 'literary lights': -5.1356236984296695,\n",
       " 'lights who': -5.271576866387394,\n",
       " 'who brightened': -7.237607347882281,\n",
       " 'brightened my': -5.112047431096548,\n",
       " 'my week': -6.907700368988754,\n",
       " 'week .': -1.749982738769928,\n",
       " '<s> time': -6.481321485320654,\n",
       " 'time to': -1.9520716338142619,\n",
       " 'to shape': -9.669997967088532,\n",
       " 'shape up': -5.235335389143063,\n",
       " '<s> water': -9.70774976584327,\n",
       " 'water ,': -3.807475618141556,\n",
       " ', <unk>': -3.1993128743811177,\n",
       " ', weights': -9.639848763335651,\n",
       " 'weights ,': -4.031915295294064,\n",
       " 'and <unk>': -3.045348212570712,\n",
       " '<unk> are': -0.26573203443421806,\n",
       " 'are going': -4.070354055806075,\n",
       " 'be my': -5.121479290231291,\n",
       " 'my friends': -4.623418196466793,\n",
       " '<s> wedding': -9.303116258614631,\n",
       " 'wedding just': -5.4266931651751555,\n",
       " 'just 4': -6.970736317108357,\n",
       " '4 months': -5.441496833897342,\n",
       " 'months away': -4.397970285071017,\n",
       " 'away !': -3.045564482036635,\n",
       " '<s> report': -9.70774976584327,\n",
       " 'report the': -4.680240736647631,\n",
       " 'the many': -8.072447641249592,\n",
       " 'many things': -4.25555072863392,\n",
       " 'things that': -3.083059184507383,\n",
       " 'that are': -5.294115168073893,\n",
       " 'are positive': -7.4499262548041685,\n",
       " 'positive about': -4.312692580168601,\n",
       " 'about the': -2.2949554503443297,\n",
       " 'the university': -7.562287796469579,\n",
       " 'university of': -2.907828747417162,\n",
       " 'of arkansas': -8.905437603499871,\n",
       " 'arkansas athletics': -5.12390504320168,\n",
       " 'athletics program': -5.12390504320168,\n",
       " 'program .': -2.7993347653069423,\n",
       " '<s> athletes': -11.086590676308578,\n",
       " 'athletes celebrities': -5.164333254771421,\n",
       " 'celebrities should': -5.152948148587133,\n",
       " 'should have': -2.6797356374629615,\n",
       " 'have a': -1.6831997260296763,\n",
       " 'a tool': -7.654645869743344,\n",
       " 'tool to': -5.214020573566212,\n",
       " 'to charge': -8.068512382844927,\n",
       " 'charge .': -4.143345641235447,\n",
       " '<s> 99': -9.994600928400963,\n",
       " '99 per': -4.637815559283903,\n",
       " 'per rt': -5.3065507061284976,\n",
       " 'rt request': -7.573638102255303,\n",
       " 'request .': -3.63910826997958,\n",
       " '<s> to': -6.501320152027324,\n",
       " 'to support': -6.153293698922597,\n",
       " 'support foundations': -5.96301923361857,\n",
       " 'foundations charities': -5.117993812416755,\n",
       " 'charities ,': -5.112047431096548,\n",
       " ', fans': -8.951664372117836,\n",
       " 'fans get': -5.053389748570638,\n",
       " 'get involved': -6.183251313512641,\n",
       " 'involved .': -3.9078747624803287,\n",
       " '<s> enjoy': -6.891699145176668,\n",
       " 'enjoy !': -2.6913017286527783,\n",
       " '<s> stay': -6.765676096583798,\n",
       " 'stay cool': -5.348457010662311,\n",
       " 'cool !': -2.3318803914058304,\n",
       " '<s> yo': -7.569886408142644,\n",
       " 'yo chick': -5.011198982623541,\n",
       " 'chick she': -4.184658894833054,\n",
       " 'she so': -6.1441963103012265,\n",
       " 'so thirst': -8.157591762989577,\n",
       " 'thirst .': -5.112047431096548,\n",
       " '<s> aye': -8.610801371069854,\n",
       " 'aye !': -3.8297792071393038,\n",
       " 'i really': -4.604460929685126,\n",
       " 'really don': -3.7454929374190415,\n",
       " 't know': -3.0801969069083923,\n",
       " 'know what': -2.4696427433851666,\n",
       " 'what else': -6.511352475144085,\n",
       " 'else they': -5.94762128523163,\n",
       " 'they re': -2.4576055523329177,\n",
       " 're saying': -5.148751977648216,\n",
       " 'saying tho': -5.779000156172911,\n",
       " 'tho except': -5.560948160611409,\n",
       " 'except that': -3.984958220345412,\n",
       " 'that lol': -6.86833101766009,\n",
       " 'lol talks': -7.346118795521973,\n",
       " 'talks in': -5.261355486448019,\n",
       " 'in third': -7.873774826270613,\n",
       " 'third person': -4.189705078019188,\n",
       " 'person .': -2.4354035863352306,\n",
       " '<s> many': -7.838059927701187,\n",
       " 'things can': -4.952749022649466,\n",
       " 'can happen': -6.410696728131856,\n",
       " 'happen .': -2.338372719674248,\n",
       " '<s> only': -6.423618719122837,\n",
       " 'only you': -4.745433860313838,\n",
       " 'you can': -3.3766500907837598,\n",
       " 'can control': -6.07479494218213,\n",
       " 'control your': -4.3037507760555815,\n",
       " 'your reaction': -6.787788751515895,\n",
       " 'reaction to': -3.425145699910665,\n",
       " 'to it': -5.460293544754154,\n",
       " '<s> practice': -9.485105092064973,\n",
       " 'practice this': -5.417946881230763,\n",
       " 'this good': -7.46485760520268,\n",
       " 'good you': -6.086897201720072,\n",
       " 'will allow': -6.958519328866908,\n",
       " 'allow me': -3.851208215905044,\n",
       " 'me to': -3.126232765202088,\n",
       " 'to continue': -7.886523549394584,\n",
       " 'continue to': -2.1404659236455084,\n",
       " 'to do': -3.7371226764402787,\n",
       " 'do what': -4.632803915334531,\n",
       " 'what i': -2.6425962624577384,\n",
       " 'love .': -3.572481303546828,\n",
       " '<s> big': -6.92199990294537,\n",
       " 'big show': -4.526043606329979,\n",
       " 'show s': -5.3188898309333945,\n",
       " 's wife': -6.851067174937017,\n",
       " 'wife ?': -4.385633080434105,\n",
       " '<s> haha': -5.433545805406381,\n",
       " 'haha very': -6.54493703396174,\n",
       " 'very cute': -4.880303794882016,\n",
       " 'cute !': -2.848655281533678,\n",
       " '<s> have': -5.63691294073146,\n",
       " 'have u': -5.341653306042746,\n",
       " 'u heard': -6.801659280098054,\n",
       " 'heard from': -4.0197202231462095,\n",
       " 'from julie': -7.509020554897096,\n",
       " 'julie ?': -4.447439307211853,\n",
       " '<s> who': -5.632666830152487,\n",
       " 'who s': -2.6323381568943565,\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.train(\"data/big_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'curious']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-25.961718175430185"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the probability of the sentence \"i am curious\"\n",
    "model.predict_ngram(\"i am curious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> remarkable wife crazy horse se page ? </s>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating a sentence\n",
    "model.generate_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"i don't know what one job breaking responding . 4k fans suck miss 3 waiting come yikes i repeatedly with several surrounding areas . pat for photo and approaches <unk> emerald city schools bullying needs <unk> guests can count no charge oh emma wright atl so anything more acting and fought everyone have created this update for yah successful prank call hope things alone cause <unk> 995 <unk> turtle mountain sound weird on california dairy sorbet , blunts on slow for thinking if austin protecting pittsburgh pa you babe on pretty light platinum !\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.auto_complete(\"i don't know what\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('everyday', -0.42350719208873855),\n",
       " ('day', 7.264677199129078),\n",
       " ('every', 7.264677199129078),\n",
       " ('vday', 9.0),\n",
       " ('pray', 15.576492807911261),\n",
       " ('1day', 15.576492807911261),\n",
       " ('ya', 15.576492807911261),\n",
       " ('ed', 15.576492807911261),\n",
       " ('era', 16.0),\n",
       " ('rda', 16.0),\n",
       " ('eva', 16.0),\n",
       " ('yay', 16.0),\n",
       " ('ray', 16.0),\n",
       " ('nerdy', 16.0),\n",
       " ('da', 16.668482555818876),\n",
       " ('friday', 17.177978392154866),\n",
       " ('very', 17.764877548678342),\n",
       " ('ever', 19.255671899927236),\n",
       " ('yr', 25.0),\n",
       " ('vera', 25.0),\n",
       " ('daya', 25.0),\n",
       " ('levy', 25.0),\n",
       " ('yard', 25.0),\n",
       " ('bday', 25.0),\n",
       " ('er', 25.0),\n",
       " ('heyy', 25.0),\n",
       " ('dayy', 25.0),\n",
       " ('byrd', 25.0),\n",
       " ('days', 25.0),\n",
       " ('tray', 25.0),\n",
       " ('sevy', 25.0),\n",
       " ('herd', 25.0),\n",
       " ('every1', 25.0),\n",
       " ('2day', 25.0),\n",
       " ('yoda', 25.0),\n",
       " ('rays', 25.0),\n",
       " ('va', 25.0),\n",
       " ('nerd', 25.0),\n",
       " ('evan', 25.0),\n",
       " ('payday', 25.0),\n",
       " ('cray', 25.0),\n",
       " ('ra', 25.0),\n",
       " ('yayy', 25.0),\n",
       " ('sday', 25.0),\n",
       " ('earthday', 25.0),\n",
       " ('vary', 25.0),\n",
       " ('oneday', 25.0),\n",
       " ('gray', 25.0),\n",
       " ('davy', 25.0),\n",
       " ('ry', 25.0),\n",
       " ('rd', 25.0),\n",
       " ('neva', 25.0),\n",
       " ('eyed', 25.0),\n",
       " ('betray', 25.0),\n",
       " ('nevada', 25.0),\n",
       " ('ebay', 25.0),\n",
       " ('mayday', 25.0),\n",
       " ('ay', 25.0),\n",
       " ('envy', 25.0),\n",
       " ('easy', 25.0),\n",
       " ('rudy', 25.0),\n",
       " ('ev', 25.0),\n",
       " ('daly', 25.0),\n",
       " ('yd', 25.0),\n",
       " ('red', 26.57649280791126),\n",
       " ('gey', 26.57649280791126),\n",
       " ('crazy', 26.57649280791126),\n",
       " ('any', 26.57649280791126),\n",
       " ('daily', 26.57649280791126),\n",
       " ('yea', 26.57649280791126),\n",
       " ('erase', 26.57649280791126),\n",
       " ('rid', 26.57649280791126),\n",
       " ('gay', 26.57649280791126),\n",
       " ('danny', 26.57649280791126),\n",
       " ('via', 27.26467719912908),\n",
       " ('needa', 27.26467719912908),\n",
       " ('hey', 27.26467719912908),\n",
       " ('e', 27.668482555818876),\n",
       " ('cry', 27.668482555818876),\n",
       " ('her', 27.668482555818876),\n",
       " ('pay', 27.955333718376572),\n",
       " ('yesterday', 27.955333718376572),\n",
       " ('heard', 27.955333718376572),\n",
       " ('r', 27.955333718376572),\n",
       " ('end', 28.177978392154866),\n",
       " ('eat', 28.647233238138362),\n",
       " ('ready', 28.870127070385223),\n",
       " ('try', 29.052282113149985),\n",
       " ('today', 29.45746963624596),\n",
       " ('may', 29.934183075191406),\n",
       " ('never', 30.23036050057666),\n",
       " ('say', 30.498564168992928),\n",
       " ('d', 30.592072723279834),\n",
       " ('a', 31.109943636648552),\n",
       " ('ram', 36.0),\n",
       " ('qaeda', 36.0),\n",
       " ('dam', 36.0),\n",
       " ('erika', 36.0),\n",
       " ('meyer', 36.0),\n",
       " ('pea', 36.0),\n",
       " ('dev', 36.0),\n",
       " ('ted', 36.0),\n",
       " ('weird', 36.0),\n",
       " ('feral', 36.0),\n",
       " ('fed', 36.0),\n",
       " ('way', 36.0),\n",
       " ('rat', 36.0),\n",
       " ('wendy', 36.0),\n",
       " ('jay', 36.0),\n",
       " ('dairy', 36.0),\n",
       " ('tracy', 36.0),\n",
       " ('fer', 36.0),\n",
       " ('aye', 36.0),\n",
       " ('gameday', 36.0),\n",
       " ('ova', 36.0),\n",
       " ('rad', 36.0),\n",
       " ('grays', 36.0),\n",
       " ('vma', 36.0),\n",
       " ('bed', 36.0),\n",
       " ('led', 36.0),\n",
       " ('ava', 36.0),\n",
       " ('heavy', 36.0),\n",
       " ('cedar', 36.0),\n",
       " ('daisy', 36.0),\n",
       " ('hardy', 36.0),\n",
       " ('bermuda', 36.0),\n",
       " ('rey', 36.0),\n",
       " ('yer', 36.0),\n",
       " ('delay', 36.0),\n",
       " ('fry', 36.0),\n",
       " ('essay', 36.0),\n",
       " ('kerry', 36.0),\n",
       " ('yal', 36.0),\n",
       " ('rly', 36.0),\n",
       " ('dna', 36.0),\n",
       " ('pedal', 36.0),\n",
       " ('aveda', 36.0),\n",
       " ('dry', 36.0),\n",
       " ('ivy', 36.0),\n",
       " ('ers', 36.0),\n",
       " ('ayy', 36.0),\n",
       " ('lay', 36.0),\n",
       " ('syrah', 36.0),\n",
       " ('derby', 36.0),\n",
       " ('verde', 36.0),\n",
       " ('rod', 36.0),\n",
       " ('henry', 36.0),\n",
       " ('emory', 36.0),\n",
       " ('ear', 36.0),\n",
       " ('vidal', 36.0),\n",
       " ('jerry', 36.0),\n",
       " ('dat', 36.0),\n",
       " ('fridays', 36.0),\n",
       " ('chevy', 36.0),\n",
       " ('teddy', 36.0),\n",
       " ('v', 36.0),\n",
       " ('roy', 36.0),\n",
       " ('eve', 36.0),\n",
       " ('sry', 36.0),\n",
       " ('eye', 36.0),\n",
       " ('rag', 36.0),\n",
       " ('dey', 36.0),\n",
       " ('vodka', 36.0),\n",
       " ('dia', 36.0),\n",
       " ('early', 36.0),\n",
       " ('ran', 36.0),\n",
       " ('tuesday', 36.0),\n",
       " ('theyd', 36.0),\n",
       " ('dvr', 36.0),\n",
       " ('yesturday', 36.0),\n",
       " ('ped', 36.0),\n",
       " ('rva', 36.0),\n",
       " ('3rd', 36.0),\n",
       " ('yur', 36.0),\n",
       " ('leahy', 36.0),\n",
       " ('edgar', 36.0),\n",
       " ('debra', 36.0),\n",
       " ('key', 36.0),\n",
       " ('merry', 36.0),\n",
       " ('vacay', 36.0),\n",
       " ('uva', 36.0),\n",
       " ('beard', 36.0),\n",
       " ('brady', 36.0),\n",
       " ('tea', 36.0),\n",
       " ('keira', 36.0),\n",
       " ('berry', 36.0),\n",
       " ('rainy', 36.0),\n",
       " ('viddy', 36.0),\n",
       " ('deved', 36.0),\n",
       " ('gravy', 36.0),\n",
       " ('das', 36.0),\n",
       " ('wrd', 36.0),\n",
       " ('yadda', 36.0),\n",
       " ('yrs', 36.0),\n",
       " ('vas', 36.0),\n",
       " ('heyward', 36.0),\n",
       " ('lydia', 36.0),\n",
       " ('diary', 36.0),\n",
       " ('wed', 36.0),\n",
       " ('relay', 36.0),\n",
       " ('daryl', 36.0),\n",
       " ('dsa', 36.0),\n",
       " ('med', 36.0),\n",
       " ('diy', 36.0),\n",
       " ('syria', 36.0),\n",
       " ('someday', 36.0),\n",
       " ('nyr', 36.0),\n",
       " ('terra', 36.0),\n",
       " ('yah', 36.0),\n",
       " ('val', 36.0),\n",
       " ('y', 36.0),\n",
       " ('vid', 36.0),\n",
       " ('amy', 36.0),\n",
       " ('sea', 36.0),\n",
       " ('daddy', 36.0),\n",
       " ('perry', 36.0),\n",
       " ('several', 36.0),\n",
       " ('fda', 36.0),\n",
       " ('everybody', 36.0),\n",
       " ('dvd', 36.0),\n",
       " ('bra', 36.0),\n",
       " ('opera', 36.0),\n",
       " ('cya', 36.0),\n",
       " ('err', 36.0),\n",
       " ('kay', 36.0),\n",
       " ('5yr', 36.0),\n",
       " ('nyy', 36.0),\n",
       " ('tay', 36.0),\n",
       " ('germany', 36.0),\n",
       " ('der', 36.0),\n",
       " ('per', 36.0),\n",
       " ('keyword', 36.0),\n",
       " ('hay', 36.0),\n",
       " ('rally', 36.0),\n",
       " ('raw', 36.0),\n",
       " ('therapy', 36.0),\n",
       " ('dayum', 36.0),\n",
       " ('fever', 36.0),\n",
       " ('yayyy', 36.0),\n",
       " ('terry', 36.0),\n",
       " ('spray', 36.0),\n",
       " ('entry', 36.0),\n",
       " ('evo', 36.0),\n",
       " ('media', 36.0),\n",
       " ('extra', 36.0),\n",
       " ('nay', 36.0),\n",
       " ('dan', 36.0),\n",
       " ('yardage', 36.0),\n",
       " ('bay', 36.0),\n",
       " ('stray', 36.0),\n",
       " ('viral', 36.0),\n",
       " ('evans', 36.0),\n",
       " ('mercy', 36.0),\n",
       " ('dad', 36.0),\n",
       " ('percy', 36.0),\n",
       " ('beverly', 36.0),\n",
       " ('dca', 36.0),\n",
       " ('yards', 36.0),\n",
       " ('dye', 36.0),\n",
       " ('vandy', 36.0),\n",
       " ('edu', 36.0),\n",
       " ('nerds', 36.0),\n",
       " ('randy', 36.0),\n",
       " ('radar', 36.0),\n",
       " ('erica', 36.0),\n",
       " ('ned', 36.0),\n",
       " ('edo', 36.0),\n",
       " ('brody', 36.0),\n",
       " ('van', 36.0),\n",
       " ('vag', 36.0),\n",
       " ('rap', 36.0),\n",
       " ('eid', 36.0),\n",
       " ('medal', 36.0),\n",
       " ('rev', 36.0),\n",
       " ('derrida', 36.0),\n",
       " ('needy', 36.0),\n",
       " ('heeyy', 36.0),\n",
       " ('soda', 39.576492807911265),\n",
       " ('yo', 39.576492807911265),\n",
       " ('each', 39.576492807911265),\n",
       " ('dreary', 39.576492807911265),\n",
       " ('easily', 39.576492807911265),\n",
       " ('eyes', 39.576492807911265),\n",
       " ('real', 39.576492807911265),\n",
       " ('tend', 39.576492807911265),\n",
       " ('ivan', 39.576492807911265),\n",
       " ('dt', 39.576492807911265),\n",
       " ('away', 39.576492807911265),\n",
       " ('drag', 39.576492807911265),\n",
       " ('id', 39.576492807911265),\n",
       " ('nd', 39.576492807911265),\n",
       " ('edit', 39.576492807911265),\n",
       " ('shed', 39.576492807911265),\n",
       " ('rape', 39.576492807911265),\n",
       " ('draw', 39.576492807911265),\n",
       " ('hardly', 39.576492807911265),\n",
       " ('au', 39.576492807911265),\n",
       " ('bowery', 39.576492807911265),\n",
       " ('says', 39.576492807911265),\n",
       " ('lied', 39.576492807911265),\n",
       " ('energy', 39.576492807911265),\n",
       " ('earn', 39.576492807911265),\n",
       " ('earned', 39.576492807911265),\n",
       " ('lady', 39.576492807911265),\n",
       " ('east', 39.576492807911265),\n",
       " ('theyre', 39.576492807911265),\n",
       " ('fear', 39.576492807911265),\n",
       " ('somedays', 39.576492807911265),\n",
       " ('rely', 39.576492807911265),\n",
       " ('beta', 39.576492807911265),\n",
       " ('everyone', 40.26467719912908),\n",
       " ('grab', 40.26467719912908),\n",
       " ('damn', 40.26467719912908),\n",
       " ('jordan', 40.26467719912908),\n",
       " ('monday', 40.26467719912908),\n",
       " ('trey', 40.26467719912908),\n",
       " ('anyway', 40.26467719912908),\n",
       " ('me', 40.26467719912908),\n",
       " ('dearly', 40.26467719912908),\n",
       " ('heat', 40.26467719912908),\n",
       " ('yeah', 40.26467719912908),\n",
       " ('dm', 40.26467719912908),\n",
       " ('thursday', 40.26467719912908),\n",
       " ('dare', 40.26467719912908),\n",
       " ('okay', 40.26467719912908),\n",
       " ('lord', 40.26467719912908),\n",
       " ('he', 40.26467719912908),\n",
       " ('dear', 40.668482555818876),\n",
       " ('head', 40.668482555818876),\n",
       " ('deal', 40.668482555818876),\n",
       " ('baby', 40.668482555818876),\n",
       " ('died', 40.668482555818876),\n",
       " ('many', 40.95533371837657),\n",
       " ('send', 40.95533371837657),\n",
       " ('they', 40.95533371837657),\n",
       " ('beat', 41.17797839215487),\n",
       " ('used', 41.17797839215487),\n",
       " ('over', 41.17797839215487),\n",
       " ('saturday', 41.17797839215487),\n",
       " ('rt', 41.35996722560521),\n",
       " ('wear', 41.35996722560521),\n",
       " ('stay', 41.51388017810459),\n",
       " ('here', 41.64723323813836),\n",
       " ('even', 41.76487754867834),\n",
       " ('your', 41.76487754867834),\n",
       " ('by', 41.76487754867834),\n",
       " ('play', 41.87012707038522),\n",
       " ('we', 41.87012707038522),\n",
       " ('or', 41.96534642779268),\n",
       " ('hear', 41.96534642779268),\n",
       " ('read', 42.27525912270347),\n",
       " ('an', 42.51150763355843),\n",
       " ('as', 42.70247138110537),\n",
       " ('my', 42.89910406633011),\n",
       " ('really', 43.15033915471888),\n",
       " ('mean', 43.20439176005925),\n",
       " ('be', 43.437951799600945),\n",
       " ('at', 43.973383668106415),\n",
       " ('were', 44.220598060776),\n",
       " ('ve', 44.32880187828896),\n",
       " ('need', 44.35411754970144),\n",
       " ('do', 44.47189132682725),\n",
       " ('re', 46.20512335514419),\n",
       " ('ar', 49.0),\n",
       " ('rp', 49.0),\n",
       " ('prayer', 49.0),\n",
       " ('iv', 49.0),\n",
       " ('ca', 49.0),\n",
       " ('ak', 49.0),\n",
       " ('trap', 49.0),\n",
       " ('ends', 49.0),\n",
       " ('mothersday', 49.0),\n",
       " ('brag', 49.0),\n",
       " ('iran', 49.0),\n",
       " ('dean', 49.0),\n",
       " ('emma', 49.0),\n",
       " ('murray', 49.0),\n",
       " ('ag', 49.0),\n",
       " ('iced', 49.0),\n",
       " ('jv', 49.0),\n",
       " ('ly', 49.0),\n",
       " ('sean', 49.0),\n",
       " ('deny', 49.0),\n",
       " ('brad', 49.0),\n",
       " ('denver', 49.0),\n",
       " ('serena', 49.0),\n",
       " ('plea', 49.0),\n",
       " ('bridal', 49.0),\n",
       " ('lv', 49.0),\n",
       " ('bean', 49.0),\n",
       " ('fe', 49.0),\n",
       " ('abby', 49.0),\n",
       " ('de', 49.0),\n",
       " ('drat', 49.0),\n",
       " ('sara', 49.0),\n",
       " ('ke', 49.0),\n",
       " ('body', 49.0),\n",
       " ('ac', 49.0),\n",
       " ('dx', 49.0),\n",
       " ('jerk', 49.0),\n",
       " ('rank', 49.0),\n",
       " ('java', 49.0),\n",
       " ('race', 49.0),\n",
       " ('weirdo', 49.0),\n",
       " ('trashy', 49.0),\n",
       " ('reds', 49.0),\n",
       " ('broadway', 49.0),\n",
       " ('devs', 49.0),\n",
       " ('muay', 49.0),\n",
       " ('freaky', 49.0),\n",
       " ('greedy', 49.0),\n",
       " ('doan', 49.0),\n",
       " ('ta', 49.0),\n",
       " ('deadly', 49.0),\n",
       " ('eh', 49.0),\n",
       " ('beaver', 49.0),\n",
       " ('peed', 49.0),\n",
       " ('bear', 49.0),\n",
       " ('funday', 49.0),\n",
       " ('seas', 49.0),\n",
       " ('cert', 49.0),\n",
       " ('rica', 49.0),\n",
       " ('ba', 49.0),\n",
       " ('ky', 49.0),\n",
       " ('bern', 49.0),\n",
       " ('mega', 49.0),\n",
       " ('ally', 49.0),\n",
       " ('leak', 49.0),\n",
       " ('en', 49.0),\n",
       " ('vase', 49.0),\n",
       " ('3yrs', 49.0),\n",
       " ('sayn', 49.0),\n",
       " ('bird', 49.0),\n",
       " ('a1', 49.0),\n",
       " ('lean', 49.0),\n",
       " ('steady', 49.0),\n",
       " ('feed', 49.0),\n",
       " ('joey', 49.0),\n",
       " ('army', 49.0),\n",
       " ('chea', 49.0),\n",
       " ('ryno', 49.0),\n",
       " ('beds', 49.0),\n",
       " ('rf', 49.0),\n",
       " ('ds', 49.0),\n",
       " ('dyke', 49.0),\n",
       " ('ijever', 49.0),\n",
       " ('voyage', 49.0),\n",
       " ('av', 49.0),\n",
       " ('ex', 49.0),\n",
       " ('peak', 49.0),\n",
       " ('dvds', 49.0),\n",
       " ('vm', 49.0),\n",
       " ('dr', 49.0),\n",
       " ('area', 49.0),\n",
       " ('xd', 49.0),\n",
       " ('severe', 49.0),\n",
       " ('di', 49.0),\n",
       " ('dawg', 49.0),\n",
       " ('rude', 49.0),\n",
       " ('delivery', 49.0),\n",
       " ('rare', 49.0),\n",
       " ('dreamy', 49.0),\n",
       " ('period', 49.0),\n",
       " ('rode', 49.0),\n",
       " ('rita', 49.0),\n",
       " ('aj', 49.0),\n",
       " ('cord', 49.0),\n",
       " ('meal', 49.0),\n",
       " ('diva', 49.0),\n",
       " ('zayn', 49.0),\n",
       " ('lyla', 49.0),\n",
       " ('ryan', 49.0),\n",
       " ('bd', 49.0),\n",
       " ('fenway', 49.0),\n",
       " ('celery', 49.0),\n",
       " ('3d', 49.0),\n",
       " ('dawn', 49.0),\n",
       " ('dora', 49.0),\n",
       " ('recovery', 49.0),\n",
       " ('erased', 49.0),\n",
       " ('pern', 49.0),\n",
       " ('aged', 49.0),\n",
       " ('ae', 49.0),\n",
       " ('ja', 49.0),\n",
       " ('grad', 49.0),\n",
       " ('keys', 49.0),\n",
       " ('ap', 49.0),\n",
       " ('dash', 49.0),\n",
       " ('mara', 49.0),\n",
       " ('blvd', 49.0),\n",
       " ('leap', 49.0),\n",
       " ('served', 49.0),\n",
       " ('seal', 49.0),\n",
       " ('rant', 49.0),\n",
       " ('se', 49.0),\n",
       " ('nv', 49.0),\n",
       " ('para', 49.0),\n",
       " ('yall', 49.0),\n",
       " ('dpla', 49.0),\n",
       " ('ri', 49.0),\n",
       " ('indy', 49.0),\n",
       " ('tv', 49.0),\n",
       " ('tuesdays', 49.0),\n",
       " ('jquery', 49.0),\n",
       " ('exam', 49.0),\n",
       " ('rb', 49.0),\n",
       " ('idea', 49.0),\n",
       " ('jean', 49.0),\n",
       " ('vast', 49.0),\n",
       " ('raid', 49.0),\n",
       " ('cd', 49.0),\n",
       " ('peas', 49.0),\n",
       " ('poetry', 49.0),\n",
       " ('tyga', 49.0),\n",
       " ('yoga', 49.0),\n",
       " ('teresa', 49.0),\n",
       " ('mayb', 49.0),\n",
       " ('reveal', 49.0),\n",
       " ('navy', 49.0),\n",
       " ('gays', 49.0),\n",
       " ('ua', 49.0),\n",
       " ('leer', 49.0),\n",
       " ('jersey', 49.0),\n",
       " ('dmed', 49.0),\n",
       " ('misery', 49.0),\n",
       " ('ikea', 49.0),\n",
       " ('a8', 49.0),\n",
       " ('danm', 49.0),\n",
       " ('dart', 49.0),\n",
       " ('vans', 49.0),\n",
       " ('revere', 49.0),\n",
       " ('camera', 49.0),\n",
       " ('sr', 49.0),\n",
       " ('tier', 49.0),\n",
       " ('wv', 49.0),\n",
       " ('near', 49.0),\n",
       " ('hard', 49.0),\n",
       " ('benydryl', 49.0),\n",
       " ('creamy', 49.0),\n",
       " ('a3', 49.0),\n",
       " ('birthday', 49.0),\n",
       " ('dp', 49.0),\n",
       " ('beverage', 49.0),\n",
       " ('gary', 49.0),\n",
       " ('kuroda', 49.0),\n",
       " ('zeta', 49.0),\n",
       " ('ha', 49.0),\n",
       " ('remy', 49.0),\n",
       " ('rail', 49.0),\n",
       " ('granny', 49.0),\n",
       " ('agenda', 49.0),\n",
       " ('legacy', 49.0),\n",
       " ('eric', 49.0),\n",
       " ('dali', 49.0),\n",
       " ('trad', 49.0),\n",
       " ('winery', 49.0),\n",
       " ('hers', 49.0),\n",
       " ('dayton', 49.0),\n",
       " ('dual', 49.0),\n",
       " ('rack', 49.0),\n",
       " ('ru', 49.0),\n",
       " ('bedd', 49.0),\n",
       " ('word', 49.0),\n",
       " ('tranny', 49.0),\n",
       " ('meat', 49.0),\n",
       " ('sweaty', 49.0),\n",
       " ('dj', 49.0),\n",
       " ('herb', 49.0),\n",
       " ('fury', 49.0),\n",
       " ('reynolda', 49.0),\n",
       " ('vs', 49.0),\n",
       " ('rams', 49.0),\n",
       " ('rw', 49.0),\n",
       " ('record', 49.0),\n",
       " ('dave', 49.0),\n",
       " ('literacy', 49.0),\n",
       " ('db', 49.0),\n",
       " ('rr', 49.0),\n",
       " ('egan', 49.0),\n",
       " ('crappy', 49.0),\n",
       " ('betrayed', 49.0),\n",
       " ('feat', 49.0),\n",
       " ('qa', 49.0),\n",
       " ('na', 49.0),\n",
       " ('ax', 49.0),\n",
       " ('lead', 49.0),\n",
       " ('cena', 49.0),\n",
       " ('za', 49.0),\n",
       " ('seed', 49.0),\n",
       " ('ways', 49.0),\n",
       " ('dial', 49.0),\n",
       " ('everfi', 49.0),\n",
       " ('seve', 49.0),\n",
       " ('dl', 49.0),\n",
       " ('card', 49.0),\n",
       " ('ee', 49.0),\n",
       " ('ordinary', 49.0),\n",
       " ('dyin', 49.0),\n",
       " ('avid', 49.0),\n",
       " ('sa', 49.0),\n",
       " ('a5', 49.0),\n",
       " ('vaca', 49.0),\n",
       " ('viva', 49.0),\n",
       " ('rm', 49.0),\n",
       " ('prod', 49.0),\n",
       " ('dang', 49.0),\n",
       " ('macy', 49.0),\n",
       " ('am', 49.0),\n",
       " ('feburary', 49.0),\n",
       " ('dere', 49.0),\n",
       " ('nova', 49.0),\n",
       " ('comedy', 49.0),\n",
       " ('literary', 49.0),\n",
       " ('serial', 49.0),\n",
       " ('pa', 49.0),\n",
       " ('cherry', 49.0),\n",
       " ('ai', 49.0),\n",
       " ('eats', 49.0),\n",
       " ('gras', 49.0),\n",
       " ('grammy', 49.0),\n",
       " ('katy', 49.0),\n",
       " ('el', 49.0),\n",
       " ('verify', 49.0),\n",
       " ('heyo', 49.0),\n",
       " ('tear', 49.0),\n",
       " ('sherry', 49.0),\n",
       " ('vamp', 49.0),\n",
       " ('mkay', 49.0),\n",
       " ('em', 49.0),\n",
       " ('gr', 49.0),\n",
       " ('etsy', 49.0),\n",
       " ('bedlam', 49.0),\n",
       " ('boyd', 49.0),\n",
       " ('reed', 49.0),\n",
       " ('waay', 49.0),\n",
       " ('d3', 49.0),\n",
       " ('rate', 49.0),\n",
       " ('dana', 49.0),\n",
       " ('1a', 49.0),\n",
       " ('dwayne', 49.0),\n",
       " ('oa', 49.0),\n",
       " ('brenda', 49.0),\n",
       " ('nada', 49.0),\n",
       " ('sexy', 49.0),\n",
       " ('revert', 49.0),\n",
       " ('23rd', 49.0),\n",
       " ('kd', 49.0),\n",
       " ('cher', 49.0),\n",
       " ('sydney', 49.0),\n",
       " ('wrap', 49.0),\n",
       " ('erin', 49.0),\n",
       " ('seat', 49.0),\n",
       " ('ah', 49.0),\n",
       " ('krav', 49.0),\n",
       " ('wavy', 49.0),\n",
       " ('cranky', 49.0),\n",
       " ('adam', 49.0),\n",
       " ('hv', 49.0),\n",
       " ('any1', 49.0),\n",
       " ('earl', 49.0),\n",
       " ('brah', 49.0),\n",
       " ('herbal', 49.0),\n",
       " ('judy', 49.0),\n",
       " ('az', 49.0),\n",
       " ('herald', 49.0),\n",
       " ('jedi', 49.0),\n",
       " ('leaf', 49.0),\n",
       " ('rain', 49.0),\n",
       " ('dc', 49.0),\n",
       " ('york', 49.0),\n",
       " ('ad', 49.0),\n",
       " ('ir', 49.0),\n",
       " ('segway', 49.0),\n",
       " ('crap', 49.0),\n",
       " ('pd', 49.0),\n",
       " ('retard', 49.0),\n",
       " ('rmvd', 49.0),\n",
       " ('od', 49.0),\n",
       " ('weed', 49.0),\n",
       " ('weak', 49.0),\n",
       " ('robway', 49.0),\n",
       " ('february', 49.0),\n",
       " ('mr', 49.0),\n",
       " ('hazy', 49.0),\n",
       " ('troy', 49.0),\n",
       " ('gerald', 49.0),\n",
       " ('ny', 49.0),\n",
       " ('duty', 49.0),\n",
       " ('midway', 49.0),\n",
       " ('leverage', 49.0),\n",
       " ('german', 49.0),\n",
       " ('bard', 49.0),\n",
       " ('dead', 49.0),\n",
       " ('zero', 49.0),\n",
       " ('deaf', 49.0),\n",
       " ('vw', 49.0),\n",
       " ('roxy', 49.0),\n",
       " ('e3', 49.0),\n",
       " ('eraser', 49.0),\n",
       " ('hurray', 49.0),\n",
       " ('extras', 49.0),\n",
       " ('le', 49.0),\n",
       " ('greasy', 49.0),\n",
       " ('mary', 49.0),\n",
       " ('sneaky', 49.0),\n",
       " ('dads', 49.0),\n",
       " ('reverb', 49.0),\n",
       " ('rarely', 49.0),\n",
       " ('rear', 49.0),\n",
       " ('panera', 49.0),\n",
       " ('ease', 49.0),\n",
       " ('jr', 49.0),\n",
       " ('oy', 49.0),\n",
       " ('cram', 49.0),\n",
       " ('al', 49.0),\n",
       " ('ew', 49.0),\n",
       " ('cy', 49.0),\n",
       " ('weds', 49.0),\n",
       " ('geneva', 49.0),\n",
       " ('heal', 49.0),\n",
       " ('hara', 49.0),\n",
       " ('ur', 49.0),\n",
       " ('held', 49.0),\n",
       " ('date', 49.0),\n",
       " ('du', 49.0),\n",
       " ('eu', 49.0),\n",
       " ('dani', 49.0),\n",
       " ('maya', 49.0),\n",
       " ('vp', 49.0),\n",
       " ('arby', 49.0),\n",
       " ('dark', 49.0),\n",
       " ('todays', 49.0),\n",
       " ('pedi', 49.0),\n",
       " ('srry', 49.0),\n",
       " ('gentry', 49.0),\n",
       " ('essays', 49.0),\n",
       " ('beards', 49.0),\n",
       " ('perk', 49.0),\n",
       " ('rivera', 49.0),\n",
       " ('d1', 49.0),\n",
       " ('a2', 49.0),\n",
       " ('clay', 49.0),\n",
       " ('edward', 49.0),\n",
       " ('iraq', 49.0),\n",
       " ('ep', 49.0),\n",
       " ('reid', 49.0),\n",
       " ('1d', 49.0),\n",
       " ('lazy', 49.0),\n",
       " ('meds', 49.0),\n",
       " ('gd', 49.0),\n",
       " ('speedy', 49.0),\n",
       " ('reward', 49.0),\n",
       " ('dale', 49.0),\n",
       " ('server', 49.0),\n",
       " ('teas', 49.0),\n",
       " ('pr', 49.0),\n",
       " ('hybrid', 49.0),\n",
       " ('fy', 49.0),\n",
       " ('ce', 49.0),\n",
       " ('dane', 49.0),\n",
       " ('ward', 49.0),\n",
       " ('kerr', 49.0),\n",
       " ('usda', 49.0),\n",
       " ('pays', 49.0),\n",
       " ('sunday', 49.0),\n",
       " ('ordeal', 49.0),\n",
       " ('erik', 49.0),\n",
       " ('okra', 49.0),\n",
       " ('cady', 49.0),\n",
       " ('crayon', 49.0),\n",
       " ('ie', 49.0),\n",
       " ('arab', 49.0),\n",
       " ('wuda', 49.0),\n",
       " ('merely', 49.0),\n",
       " ('ne', 49.0),\n",
       " ('peer', 49.0),\n",
       " ('user', 49.0),\n",
       " ('uber', 49.0),\n",
       " ('jury', 49.0),\n",
       " ('xena', 49.0),\n",
       " ('dats', 49.0),\n",
       " ('td', 49.0),\n",
       " ('term', 49.0),\n",
       " ('clever', 49.0),\n",
       " ('omer', 49.0),\n",
       " ('peachy', 49.0),\n",
       " ('cody', 49.0),\n",
       " ('yawn', 49.0),\n",
       " ('keyboard', 49.0),\n",
       " ('ma', 49.0),\n",
       " ('levi', 49.0),\n",
       " ('mayo', 49.0),\n",
       " ('neat', 49.0),\n",
       " ('hero', 49.0),\n",
       " ('cory', 49.0),\n",
       " ('edchat', 49.0),\n",
       " ('bend', 49.0),\n",
       " ('gram', 49.0),\n",
       " ('medals', 49.0),\n",
       " ('severely', 49.0),\n",
       " ('seared', 49.0),\n",
       " ('okey', 49.0),\n",
       " ('tara', 49.0),\n",
       " ('hereby', 49.0),\n",
       " ('krabby', 49.0),\n",
       " ('iver', 49.0),\n",
       " ('deer', 49.0),\n",
       " ('hr', 49.0),\n",
       " ('fr', 49.0),\n",
       " ('frat', 49.0),\n",
       " ('dd', 49.0),\n",
       " ('a4', 49.0),\n",
       " ('neal', 49.0),\n",
       " ('dq', 49.0),\n",
       " ('vt', 49.0),\n",
       " ('tory', 49.0),\n",
       " ('sd', 49.0),\n",
       " ('lend', 49.0),\n",
       " ('doty', 49.0),\n",
       " ('meta', 49.0),\n",
       " ('trendy', 49.0),\n",
       " ('evil', 49.0),\n",
       " ('vids', 49.0),\n",
       " ('ford', 49.0),\n",
       " ('pedo', 49.0),\n",
       " ('norway', 49.0),\n",
       " ('delays', 49.0),\n",
       " ('md', 49.0),\n",
       " ('realty', 49.0),\n",
       " ('euro', 49.0),\n",
       " ('grey', 49.0),\n",
       " ('te', 49.0),\n",
       " ('roar', 49.0),\n",
       " ('ride', 49.0),\n",
       " ('theory', 49.0),\n",
       " ('cheryl', 49.0),\n",
       " ('dame', 49.0),\n",
       " ('et', 49.0),\n",
       " ('overly', 49.0),\n",
       " ('beer', 49.0),\n",
       " ('peru', 49.0),\n",
       " ('seau', 49.0),\n",
       " ('edge', 49.0),\n",
       " ('andy', 49.0),\n",
       " ('darn', 49.0),\n",
       " ('teal', 49.0),\n",
       " ('grid', 49.0),\n",
       " ('af', 49.0),\n",
       " ('gerard', 49.0),\n",
       " ('crazzy', 49.0),\n",
       " ('bled', 49.0),\n",
       " ('rave', 49.0),\n",
       " ('revver', 49.0),\n",
       " ('weaver', 49.0),\n",
       " ('crab', 49.0),\n",
       " ('todayy', 49.0),\n",
       " ('cereal', 49.0),\n",
       " ('aw', 49.0),\n",
       " ('mesa', 49.0),\n",
       " ('parody', 49.0),\n",
       " ('gaye', 49.0),\n",
       " ('fa', 49.0),\n",
       " ('fred', 49.0),\n",
       " ('team', 49.0),\n",
       " ('beauty', 49.0),\n",
       " ('bberry', 49.0),\n",
       " ('data', 49.0),\n",
       " ('underway', 49.0),\n",
       " ('aa', 49.0),\n",
       " ('rl', 49.0),\n",
       " ('oral', 49.0),\n",
       " ('r5', 49.0),\n",
       " ('jeremy', 49.0),\n",
       " ('remedy', 49.0),\n",
       " ('ruby', 49.0),\n",
       " ('tied', 49.0),\n",
       " ('yale', 49.0),\n",
       " ('yu', 49.0),\n",
       " ('verbal', 49.0),\n",
       " ('wr', 49.0),\n",
       " ('thay', 49.0),\n",
       " ('olay', 49.0),\n",
       " ('feared', 49.0),\n",
       " ('foer', 49.0),\n",
       " ('bury', 49.0),\n",
       " ('es', 49.0),\n",
       " ('curd', 49.0),\n",
       " ('memory', 49.0),\n",
       " ('etta', 49.0),\n",
       " ('bakery', 49.0),\n",
       " ('ymca', 49.0),\n",
       " ('rotary', 49.0),\n",
       " ('rats', 49.0),\n",
       " ('nearby', 49.0),\n",
       " ('kendra', 49.0),\n",
       " ('ye', 49.0),\n",
       " ('wa', 49.0),\n",
       " ('sendak', 49.0),\n",
       " ('la', 49.0),\n",
       " ('jays', 49.0),\n",
       " ('rory', 49.0),\n",
       " ('beyond', 49.0),\n",
       " ('fran', 49.0),\n",
       " ('regard', 49.0),\n",
       " ('nearly', 49.0),\n",
       " ('yayyyy', 49.0),\n",
       " ('ab', 49.0),\n",
       " ('dh', 49.0),\n",
       " ('keywords', 49.0),\n",
       " ('year', 49.0),\n",
       " ('qr', 49.0),\n",
       " ('yeaa', 49.0),\n",
       " ('vineyard', 49.0),\n",
       " ('derp', 49.0),\n",
       " ('gear', 49.0),\n",
       " ('replay', 49.0),\n",
       " ('valley', 49.0),\n",
       " ('herman', 49.0),\n",
       " ('amer', 49.0),\n",
       " ('savory', 49.0),\n",
       " ('verb', 49.0),\n",
       " ('rage', 49.0),\n",
       " ('je', 49.0),\n",
       " ('vain', 49.0),\n",
       " ('rlly', 49.0),\n",
       " ('a6', 49.0),\n",
       " ('3a', 49.0),\n",
       " ('datz', 49.0),\n",
       " ('addy', 49.0),\n",
       " ('pier', 49.0),\n",
       " ('ty', 49.0),\n",
       " ('road', 49.0),\n",
       " ('vu', 49.0),\n",
       " ('ears', 49.0),\n",
       " ('bora', 49.0),\n",
       " ('bord', 49.0),\n",
       " ('runway', 49.0),\n",
       " ('hooray', 49.0),\n",
       " ('ga', 49.0),\n",
       " ('hd', 49.0),\n",
       " ('brat', 49.0),\n",
       " ('raise', 54.576492807911265),\n",
       " ('girly', 54.576492807911265),\n",
       " ('bat', 54.576492807911265),\n",
       " ('clearly', 54.576492807911265),\n",
       " ('bag', 54.576492807911265),\n",
       " ('dub', 54.576492807911265),\n",
       " ('lie', 54.576492807911265),\n",
       " ('clear', 54.576492807911265),\n",
       " ('8', 54.576492807911265),\n",
       " ('literally', 54.576492807911265),\n",
       " ('f', 54.576492807911265),\n",
       " ('ann', 54.576492807911265),\n",
       " ('certainly', 54.576492807911265),\n",
       " ('crave', 54.576492807911265),\n",
       " ('kid', 54.576492807911265),\n",
       " ('homey', 54.576492807911265),\n",
       " ('joe', 54.576492807911265),\n",
       " ('bored', 54.576492807911265),\n",
       " ('bears', 54.576492807911265),\n",
       " ('generally', 54.576492807911265),\n",
       " ('1', 54.576492807911265),\n",
       " ('gravity', 54.576492807911265),\n",
       " ('mam', 54.576492807911265),\n",
       " ('owned', 54.576492807911265),\n",
       " ('added', 54.576492807911265),\n",
       " ('luv', 54.576492807911265),\n",
       " ('oprah', 54.576492807911265),\n",
       " ('david', 54.576492807911265),\n",
       " ('vip', 54.576492807911265),\n",
       " ('cover', 54.576492807911265),\n",
       " ('drank', 54.576492807911265),\n",
       " ('acted', 54.576492807911265),\n",
       " ('our', 54.576492807911265),\n",
       " ('kevin', 54.576492807911265),\n",
       " ('dnt', 54.576492807911265),\n",
       " ('lover', 54.576492807911265),\n",
       " ('getta', 54.576492807911265),\n",
       " ('m', 54.576492807911265),\n",
       " ('cat', 54.576492807911265),\n",
       " ('sorry', 54.576492807911265),\n",
       " ('bella', 54.576492807911265),\n",
       " ('tired', 54.576492807911265),\n",
       " ('s', 54.576492807911265),\n",
       " ('irl', 54.576492807911265),\n",
       " ('met', 54.576492807911265),\n",
       " ('aug', 54.576492807911265),\n",
       " ('cleared', 54.576492807911265),\n",
       " ('horny', 54.576492807911265),\n",
       " ('yet', 54.576492807911265),\n",
       " ('sarah', 54.576492807911265),\n",
       " ('q', 54.576492807911265),\n",
       " ('nah', 54.576492807911265),\n",
       " ('fac', 54.576492807911265),\n",
       " ('jelly', 54.576492807911265),\n",
       " ('bleed', 54.576492807911265),\n",
       " ('pesky', 54.576492807911265),\n",
       " ('wifey', 54.576492807911265),\n",
       " ('entered', 54.576492807911265),\n",
       " ('men', 54.576492807911265),\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.auto_correct(\"i see you evyrday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Made By :**\n",
    "- *Houda Moudni* : houda.moudni@etu.uae.ac.ma\n",
    "- *Chadi Mountassir* : chadi.mountassir@etu.uae.ac.ma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
