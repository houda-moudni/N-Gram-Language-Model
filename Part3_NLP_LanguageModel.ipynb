{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2-NLP Language Model : *POS Tagging*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from conllu import parse\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/DATA_3/train.conllu', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()\n",
    "\n",
    "parsed_data = parse(data)\n",
    "\n",
    "sentences = []\n",
    "forms = []\n",
    "lemmas = []\n",
    "upos = []\n",
    "\n",
    "for sentence in parsed_data:\n",
    "    sent = []\n",
    "    form = []\n",
    "    lemma = []\n",
    "    upos_tag = []\n",
    "    for token in sentence:\n",
    "        sent.append(token['sentence'])\n",
    "        form.append(token['form'])\n",
    "        lemma.append(token['lemma'])\n",
    "        upos_tag.append(token['upostag'])\n",
    "    sentences.append(' '.join(sent))\n",
    "    forms.append(form)\n",
    "    lemmas.append(lemma)\n",
    "    upos.append(upos_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Les commotions cérébrales sont devenu si courantes dans ce sport qu' on les considére presque comme la routine .\",\n",
       " \"L' œuvre est située dans la galerie des de les batailles , dans le château de Versailles .\",\n",
       " \"Le comportement de la Turquie vis-à-vis du de le problème palestinien a fait qu' elle n' est plus en odeur de sainteté auprès de la communauté juive en générale , et américaine en particulier .\",\n",
       " 'Toutefois , les filles adorent les desserts .',\n",
       " \"Ismene entre et annonce que c' est Farnace qui a mis le feu à la flotte romaine .\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_data = {\n",
    "    'sentences':sentences,\n",
    "    'forms':forms,\n",
    "    'lemmas':lemmas,\n",
    "    'UPOS': upos\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>forms</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>UPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les commotions cérébrales sont devenu si coura...</td>\n",
       "      <td>[Les, commotions, cérébrales, sont, devenu, si...</td>\n",
       "      <td>[le, commotion, cérébral, être, devenir, si, c...</td>\n",
       "      <td>[DET, NFP, ADJFP, AUX, VPPMS, ADV, ADJFP, PREP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L' œuvre est située dans la galerie des de les...</td>\n",
       "      <td>[L', œuvre, est, située, dans, la, galerie, de...</td>\n",
       "      <td>[le, œuvre, être, situer, dans, le, galerie, _...</td>\n",
       "      <td>[DET, NFS, AUX, VPPFS, PREP, DETFS, NFS, _, PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le comportement de la Turquie vis-à-vis du de ...</td>\n",
       "      <td>[Le, comportement, de, la, Turquie, vis-à-vis,...</td>\n",
       "      <td>[le, comportement, de, le, Turquie, vis-à-vis,...</td>\n",
       "      <td>[DETMS, NMS, PREP, DETFS, PROPN, ADV, _, PREP,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toutefois , les filles adorent les desserts .</td>\n",
       "      <td>[Toutefois, ,, les, filles, adorent, les, dess...</td>\n",
       "      <td>[toutefois, ,, le, fille, adorer, le, dessert, .]</td>\n",
       "      <td>[ADV, PUNCT, DET, NFP, VERB, DET, NMP, YPFOR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ismene entre et annonce que c' est Farnace qui...</td>\n",
       "      <td>[Ismene, entre, et, annonce, que, c', est, Far...</td>\n",
       "      <td>[Ismene, entrer, et, annoncer, que, ce, être, ...</td>\n",
       "      <td>[PROPN, VERB, COCO, VERB, COSUB, PDEMMS, AUX, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14444</th>\n",
       "      <td>Le 28 mars 1792 , ces territoires formèrent de...</td>\n",
       "      <td>[Le, 28, mars, 1792, ,, ces, territoires, form...</td>\n",
       "      <td>[le, 28, mars, 1792, ,, ce, territoire, former...</td>\n",
       "      <td>[DETMS, CHIF, NOUN, CHIF, PUNCT, DET, NMP, VER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14445</th>\n",
       "      <td>Ce débutant de l' année 1983 et double All-Sta...</td>\n",
       "      <td>[Ce, débutant, de, l', année, 1983, et, double...</td>\n",
       "      <td>[ce, débutant, de, le, année, 1983, et, double...</td>\n",
       "      <td>[PDEMMS, NMS, PREP, DET, NFS, CHIF, COCO, ADJ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14446</th>\n",
       "      <td>La population est alors indigène et fait parti...</td>\n",
       "      <td>[La, population, est, alors, indigène, et, fai...</td>\n",
       "      <td>[le, population, être, alors, indigène, et, fa...</td>\n",
       "      <td>[DETFS, NFS, AUX, ADV, ADJFS, COCO, VERB, NFS,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14447</th>\n",
       "      <td>Mais MSI propose aussi , pour 699 euros , une ...</td>\n",
       "      <td>[Mais, MSI, propose, aussi, ,, pour, 699, euro...</td>\n",
       "      <td>[mais, MSI, proposer, aussi, ,, pour, 699, eur...</td>\n",
       "      <td>[COCO, PROPN, VERB, ADV, PUNCT, PREP, CHIF, NM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14448</th>\n",
       "      <td>Selon une première hypothèse , l' origine est ...</td>\n",
       "      <td>[Selon, une, première, hypothèse, ,, l', origi...</td>\n",
       "      <td>[selon, un, premier, hypothèse, ,, le, origine...</td>\n",
       "      <td>[PREP, DINTFS, ADJFS, NFS, PUNCT, DET, NFS, AU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14449 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences  \\\n",
       "0      Les commotions cérébrales sont devenu si coura...   \n",
       "1      L' œuvre est située dans la galerie des de les...   \n",
       "2      Le comportement de la Turquie vis-à-vis du de ...   \n",
       "3          Toutefois , les filles adorent les desserts .   \n",
       "4      Ismene entre et annonce que c' est Farnace qui...   \n",
       "...                                                  ...   \n",
       "14444  Le 28 mars 1792 , ces territoires formèrent de...   \n",
       "14445  Ce débutant de l' année 1983 et double All-Sta...   \n",
       "14446  La population est alors indigène et fait parti...   \n",
       "14447  Mais MSI propose aussi , pour 699 euros , une ...   \n",
       "14448  Selon une première hypothèse , l' origine est ...   \n",
       "\n",
       "                                                   forms  \\\n",
       "0      [Les, commotions, cérébrales, sont, devenu, si...   \n",
       "1      [L', œuvre, est, située, dans, la, galerie, de...   \n",
       "2      [Le, comportement, de, la, Turquie, vis-à-vis,...   \n",
       "3      [Toutefois, ,, les, filles, adorent, les, dess...   \n",
       "4      [Ismene, entre, et, annonce, que, c', est, Far...   \n",
       "...                                                  ...   \n",
       "14444  [Le, 28, mars, 1792, ,, ces, territoires, form...   \n",
       "14445  [Ce, débutant, de, l', année, 1983, et, double...   \n",
       "14446  [La, population, est, alors, indigène, et, fai...   \n",
       "14447  [Mais, MSI, propose, aussi, ,, pour, 699, euro...   \n",
       "14448  [Selon, une, première, hypothèse, ,, l', origi...   \n",
       "\n",
       "                                                  lemmas  \\\n",
       "0      [le, commotion, cérébral, être, devenir, si, c...   \n",
       "1      [le, œuvre, être, situer, dans, le, galerie, _...   \n",
       "2      [le, comportement, de, le, Turquie, vis-à-vis,...   \n",
       "3      [toutefois, ,, le, fille, adorer, le, dessert, .]   \n",
       "4      [Ismene, entrer, et, annoncer, que, ce, être, ...   \n",
       "...                                                  ...   \n",
       "14444  [le, 28, mars, 1792, ,, ce, territoire, former...   \n",
       "14445  [ce, débutant, de, le, année, 1983, et, double...   \n",
       "14446  [le, population, être, alors, indigène, et, fa...   \n",
       "14447  [mais, MSI, proposer, aussi, ,, pour, 699, eur...   \n",
       "14448  [selon, un, premier, hypothèse, ,, le, origine...   \n",
       "\n",
       "                                                    UPOS  \n",
       "0      [DET, NFP, ADJFP, AUX, VPPMS, ADV, ADJFP, PREP...  \n",
       "1      [DET, NFS, AUX, VPPFS, PREP, DETFS, NFS, _, PR...  \n",
       "2      [DETMS, NMS, PREP, DETFS, PROPN, ADV, _, PREP,...  \n",
       "3          [ADV, PUNCT, DET, NFP, VERB, DET, NMP, YPFOR]  \n",
       "4      [PROPN, VERB, COCO, VERB, COSUB, PDEMMS, AUX, ...  \n",
       "...                                                  ...  \n",
       "14444  [DETMS, CHIF, NOUN, CHIF, PUNCT, DET, NMP, VER...  \n",
       "14445  [PDEMMS, NMS, PREP, DET, NFS, CHIF, COCO, ADJ,...  \n",
       "14446  [DETFS, NFS, AUX, ADV, ADJFS, COCO, VERB, NFS,...  \n",
       "14447  [COCO, PROPN, VERB, ADV, PUNCT, PREP, CHIF, NM...  \n",
       "14448  [PREP, DINTFS, ADJFS, NFS, PUNCT, DET, NFS, AU...  \n",
       "\n",
       "[14449 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_df = pd.DataFrame(POS_data)\n",
    "POS_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Create the Transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_matrix(unique_pos, adjacent_combinations, alpha, print_transition_matrix=False):\n",
    "\n",
    "    ''' \n",
    "    This function aims to calculate the transition matrix.\n",
    "    Arguments\n",
    "    ---------\n",
    "        alpha: number used for smoothing\n",
    "        tag_counts: a dictionary mapping each tag to its respective count\n",
    "        transition_counts: transition count for the previous word and tag\n",
    "        print_transition_matrix: a boolean if you want to print the transition matrix\n",
    "    Returns\n",
    "    -------\n",
    "        transition_matrix : matrix of dimension (num_tags,num_tags)\n",
    "    '''\n",
    "    \n",
    "    num_tags = len(unique_pos)\n",
    "    transition_matrix = np.zeros((num_tags, num_tags))\n",
    "\n",
    "    possible_combo = Counter(adjacent_combinations)\n",
    "\n",
    "    for i, tag1 in enumerate(unique_pos):\n",
    "        for j, tag2 in enumerate(unique_pos):\n",
    "            \n",
    "            count = possible_combo.get((tag1, tag2), 0)\n",
    "            count_prev_tag = sum(1 for t1, t2 in adjacent_combinations if t1 == tag1)\n",
    "            transition_matrix[i][j] = (count + alpha) / (count_prev_tag + alpha * num_tags)\n",
    "\n",
    "    if print_transition_matrix:\n",
    "        print(transition_matrix)\n",
    "\n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752\n"
     ]
    }
   ],
   "source": [
    "unique_pos = sorted(set(chain.from_iterable(upos)))\n",
    "adjacent_combinations = [(tag1, tag2) for tags in upos for tag1, tag2 in zip(tags, tags[1:])]\n",
    "print(len(Counter(adjacent_combinations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.36996399e-02 1.06353853e-03 1.05300845e-05 ... 1.06353853e-03\n",
      "  1.43219679e-01 3.47598088e-02]\n",
      " [7.52622947e-04 3.37032793e-02 1.87594078e-03 ... 3.74439277e-06\n",
      "  1.27687538e-01 4.15665042e-02]\n",
      " [2.84112593e-04 1.41349549e-06 3.81657917e-02 ... 1.42763044e-04\n",
      "  1.06720323e-01 5.07459016e-02]\n",
      " ...\n",
      " [1.77110331e-04 3.52467094e-04 5.27823858e-04 ... 1.43443586e-01\n",
      "  1.16263288e-01 8.59423497e-03]\n",
      " [5.35905681e-04 5.35905681e-04 5.35905681e-04 ... 5.35905681e-04\n",
      "  5.35905681e-04 5.35905681e-04]\n",
      " [1.03224102e-06 1.03224102e-06 1.03224102e-06 ... 1.03224102e-06\n",
      "  1.03224102e-06 1.03224102e-06]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.36996399e-02, 1.06353853e-03, 1.05300845e-05, ...,\n",
       "        1.06353853e-03, 1.43219679e-01, 3.47598088e-02],\n",
       "       [7.52622947e-04, 3.37032793e-02, 1.87594078e-03, ...,\n",
       "        3.74439277e-06, 1.27687538e-01, 4.15665042e-02],\n",
       "       [2.84112593e-04, 1.41349549e-06, 3.81657917e-02, ...,\n",
       "        1.42763044e-04, 1.06720323e-01, 5.07459016e-02],\n",
       "       ...,\n",
       "       [1.77110331e-04, 3.52467094e-04, 5.27823858e-04, ...,\n",
       "        1.43443586e-01, 1.16263288e-01, 8.59423497e-03],\n",
       "       [5.35905681e-04, 5.35905681e-04, 5.35905681e-04, ...,\n",
       "        5.35905681e-04, 5.35905681e-04, 5.35905681e-04],\n",
       "       [1.03224102e-06, 1.03224102e-06, 1.03224102e-06, ...,\n",
       "        1.03224102e-06, 1.03224102e-06, 1.03224102e-06]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix = get_transition_matrix(unique_pos, adjacent_combinations, alpha=0.01, print_transition_matrix=True)\n",
    "transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Create the emisson matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_matrix(alpha, tag_counts, emission_counts, vocab, print_emission_matrix=False):\n",
    "\n",
    "    '''\n",
    "    This function aims to calculate the emission matrix.\n",
    "    Arguments\n",
    "    --------- \n",
    "        alpha: tuning parameter used in smoothing \n",
    "        tag_counts: a dictionary mapping each tag to its respective count\n",
    "        emission_counts: a dictionary where the keys are (tag, word) and the values are the counts\n",
    "        vocab: a dictionary where keys are words in vocabulary and value is an index\n",
    "        print_emission_matrix: a boolean if you want to print the emission matrix\n",
    "    Returns\n",
    "    -------\n",
    "        emission_matrix: a matrix of dimension (num_tags, len(vocab))\n",
    "    '''\n",
    "    \n",
    "    num_tags = len(tag_counts)\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    num_words = len(vocab)\n",
    "    \n",
    "    emission_matrix = np.zeros((num_tags, num_words))\n",
    "    emis_keys = set(list(emission_counts.keys()))\n",
    "    \n",
    "    for i in range(num_tags):\n",
    "        for word in vocab:  \n",
    "            \n",
    "            j = vocab[word]\n",
    "            count = 0      \n",
    "            key = (word, all_tags[i])\n",
    "\n",
    "            if key in emis_keys:\n",
    "                count = emission_counts[key]\n",
    "                \n",
    "            count_tag = tag_counts[all_tags[i]]\n",
    "            emission_matrix[i,j] = (count + alpha) / (count_tag + alpha * num_words)\n",
    "\n",
    "    if print_emission_matrix:\n",
    "        print(emission_matrix)\n",
    "\n",
    "\n",
    "    return emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique tags and their counts\n",
    "tag_counts = Counter((chain.from_iterable(POS_data['UPOS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique words and create a vocabulary mapping\n",
    "words = [token for sublist in POS_data['forms'] for token in sublist]\n",
    "vocab = {word: idx for idx, word in enumerate(set(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the smoothing parameter alpha\n",
    "alpha = 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the UPOS list iterable\n",
    "upos_column = chain.from_iterable(POS_data['UPOS'])\n",
    "emission_counts = Counter()\n",
    "\n",
    "# Iterate over each pair of (tag, lemma) in upos_column and corresponding lemma\n",
    "for forms_list,tag  in zip(POS_data['lemmas'],upos_column):\n",
    "    for forms,tag  in zip(forms_list,unique_pos):\n",
    "        emission_counts[(forms,tag)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_matrix = get_emission_matrix(alpha, tag_counts, emission_counts, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.27066505e-06, 7.27066505e-06, 7.27066505e-06, ...,\n",
       "        7.27066505e-06, 7.27066505e-06, 7.27066505e-06],\n",
       "       [3.23165470e-06, 3.23165470e-06, 3.23165470e-06, ...,\n",
       "        3.23165470e-06, 3.26397125e-04, 3.23165470e-06],\n",
       "       [1.33202085e-06, 1.33202085e-06, 1.33202085e-06, ...,\n",
       "        1.33202085e-06, 1.33202085e-06, 1.33202085e-06],\n",
       "       ...,\n",
       "       [1.62988824e-06, 1.62988824e-06, 1.62988824e-06, ...,\n",
       "        1.62988824e-06, 1.62988824e-06, 1.62988824e-06],\n",
       "       [7.25510923e-07, 7.25510923e-07, 7.25510923e-07, ...,\n",
       "        7.25510923e-07, 7.25510923e-07, 7.25510923e-07],\n",
       "       [9.89081529e-07, 9.89081529e-07, 9.89081529e-07, ...,\n",
       "        9.89081529e-07, 9.89081529e-07, 9.89081529e-07]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('emission_matrix.txt', emission_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Viterbi algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(obs, start_prob, trans_prob, emit_prob):\n",
    "\n",
    "    \"\"\"\n",
    "    Viterbi algorithm for finding the most likely sequence of hidden states\n",
    "    that generated a sequence of observed events.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    obs: list of observed events\n",
    "    states: list of possible hidden states\n",
    "    start_prob: initial probability distribution of states\n",
    "    trans_prob: transition probabilities between states\n",
    "    emit_prob: emission probabilities of observing events from states\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    path: most likely sequence of hidden states\n",
    "    \"\"\"\n",
    "    \n",
    "    T = len(obs)\n",
    "    N = len(trans_prob)\n",
    "    \n",
    "    # Initialize matrices for probabilities and backpointers\n",
    "    V = np.zeros((N, T))\n",
    "    backpointers = np.zeros((N, T), dtype=int)\n",
    "    \n",
    "    # Initialize first column of V matrix\n",
    "    for i in range(N):\n",
    "        V[i, 0] = start_prob[i] * emit_prob[i][0]\n",
    "        backpointers[i, 0] = 0\n",
    "    \n",
    "    # Recursively fill up the V matrix and backpointers\n",
    "    for t in range(1, T):\n",
    "        for j in range(N):\n",
    "            prob = [V[i, t-1] * trans_prob[i][j] * emit_prob[j][t] for i in range(N)]\n",
    "            V[j, t] = max(prob)\n",
    "            backpointers[j, t] = np.argmax(prob)\n",
    "    \n",
    "    \n",
    "    # Backtrack to find the most likely path\n",
    "    path = [np.argmax(V[:, T-1])]\n",
    "    for t in range(T-1, 0, -1):\n",
    "        p = path[0]\n",
    "        path.insert(0, backpointers[p, t])\n",
    "        path = path\n",
    "        \n",
    "    print(path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Create the Sentence Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagger_sentence(sentence_as_list):\n",
    "    \n",
    "    T = len(transition_matrix)\n",
    "\n",
    "    # extract the emition matrix for the sentence\n",
    "    # extract the starting probability of each tag\n",
    "    # use virbeti's algorithm to find the path of the taggs for each word (token) as indexes\n",
    "    # locate the taggs and return them\n",
    "\n",
    "    indexed_list_of_vocab = [word for word in vocab.keys()]\n",
    "\n",
    "    sentence_emition_matrix = np.zeros((T,len(sentence_as_list))) # emition matrix for the given sentence\n",
    "\n",
    "    obs = []\n",
    "    for i, word in enumerate(sentence_as_list):\n",
    "        column_index = indexed_list_of_vocab.index(word)\n",
    "        for j in range(T):\n",
    "            sentence_emition_matrix[j,i] = emission_matrix[j,column_index]\n",
    "        obs.append(column_index)\n",
    "\n",
    "\n",
    "    start_prob = np.zeros(T)\n",
    "\n",
    "    # in order to get the starting probability we will calculate how frequent\n",
    "    # each tag start, let's do it \n",
    "\n",
    "    for _, row in POS_df.iterrows():\n",
    "        first_pos_tag = row['UPOS'][0]\n",
    "        index = unique_pos.index(first_pos_tag)\n",
    "        start_prob[index] += 1\n",
    "\n",
    "    start_prob = start_prob/sum(start_prob) \n",
    "\n",
    "    \n",
    "    path = viterbi(obs,start_prob,transition_matrix,sentence_emition_matrix)\n",
    "\n",
    "    upos = []\n",
    "\n",
    "    for i in path:\n",
    "        upos.append(unique_pos[i])\n",
    "\n",
    "    return upos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 33, 45]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['COSUB', 'PPER1S', 'PREFS']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = tagger_sentence([\"Vous\",\"suis\",\"belle\"])\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Made By :**\n",
    "- *Houda Moudni* : houda.moudni@etu.uae.ac.ma\n",
    "- *Chadi Mountassir* : chadi.mountassir@etu.uae.ac.ma\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
